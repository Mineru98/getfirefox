{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75f1ddab",
   "metadata": {},
   "source": [
    "# 자연어 처리 개발 준비\n",
    "## tf.keras.layers.Dense\n",
    "`tf.keras.layers.Dense`에서 Dense는 신경망 구조의 가장 기본적인 형태를 의미한다.\n",
    "즉, 아래의 수식을 만족하는 기본적인 신경망 형태의 층을 만드는 함수이다.\n",
    "\n",
    "$$y = f(Wx+b)$$\n",
    "\n",
    "위의 수식에서 x와 b는 각각 입력 벡터, 편향 벡터이며 W는 가중치 행렬이 된다.\n",
    "즉, 가중치와 입력 벡터를 곱한 후 편향을 더해준다. 그리고 그 값에 f라는 활성화 함수를 적용하는 구조다.\n",
    "위 수식을 그림으로 보면 아래와 같은 은닉층이 없는 간단한 신경망 형태가 된다.\n",
    "\n",
    "\n",
    "<img src=\"DenseLayer.svg\" alt=\"DenseLayer\"/>\n",
    "\n",
    "위 그림에서 왼쪽 노드들이 입력값인 x가 되고 오른쪽 노드들이 y가 된다.\n",
    "그리고 중간에 있는 선이 가중치를 곱하는 과정을 의미하고, 여기서 곱해지는 가중치들이 앞 수식의 W가 된다.\n",
    "\n",
    "이러한 Dense 층을 구성하는 기본적인 방법은 가중치인 W와 b를 각각 변수로 선언한 후 행렬 곱을 통해 구하는 방법이다.\n",
    "다음과 같이 코드를 작성해서 직접 가중치 변수를 모두 정의해야 한다.\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "\n",
    "W = tf.Variable(tf.random.uniform([5, 10], -1, 1))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "y = tf.matmul(W, x) + b\n",
    "```\n",
    "\n",
    "위왁 ㅏㅌ이 모든 변수들을 선언하고 하나하나 직접 곱하고, 더해야 한다.\n",
    "하지만 텐서플로의 Dense를 이용하면 한 줄로 위의 코드를 작성할 수 있다.\n",
    "이 경우 내부적으로 변수를 생성하고 연산을 진행한다.\n",
    "아울러 인자 설정에 따라 활성화 함수 설정, 초기화 방법, 정규화 방법 등 다양한 기능을 쉽게 사용할 수 있게 구성돼 있다.\n",
    "\n",
    "케라스의 Dense를 사용하려면 우선 객체를 생성해야 한다.\n",
    "\n",
    "```python\n",
    "dense = tf.keras.layers.Dense(...)\n",
    "```\n",
    "\n",
    "이렇게 생성한 Dense 층을 객체에 입력값을 넣어야 한다.\n",
    "입력값을 넣기 위해서는 객체를 생성할 때 함께 넣거나 생성한 후 따로 적용하는 방법이 있다.\n",
    "\n",
    "```python\n",
    "# 방법 1\n",
    "dense = tf.keras.layers.Dense(...)\n",
    "output = dense(input)\n",
    "# 방법 2\n",
    "output = tf.keras.layers.Dense(...)(input)\n",
    "```\n",
    "\n",
    "Dense 층을 만들 때 여러 인자를 통해 가중치와 편향 초기화 방법, 활성화 함수의 종류 등 여러 가지를 옵션으로 정할 수 있다.\n",
    "객체를 생성할 때 지정할 수 있는 인자는 다음과 같다.\n",
    "\n",
    "```python\n",
    "__init__(\n",
    "    units, activation=None, use_bias=True,\n",
    "    kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros', kernel_regularizer=None,\n",
    "    bias_regularizer=None, activity_regularizer=None, kernel_constraint=None,\n",
    "    bias_constraint=None, **kwargs\n",
    ")\n",
    "```\n",
    "\n",
    "- units : 출력 값의 크기, Integer 혹은 Long 형태.\n",
    "- activation : 활성화 함수.\n",
    "- use_bias : 편향을 사용할지 여부. Boolean 값 형태.\n",
    "- kernel_initializer : 가중치 초기화 함수\n",
    "- bias_initializer : 편향 초기화 함수\n",
    "- kernel_regularizer : 가중치 정규화 방법\n",
    "- bias_regularizer : 편향 정규화 방법\n",
    "- activity_regularizer : 출력 값 정규화 방법\n",
    "- kernel_constraint : Optimizer에 의해 업데이트 된 이후에 가중치에 적용되는 부가적인 제약 함수\n",
    "- bias_constraint : Optimizer에 의해 업데이트 된 이후에 편향에 적용되는 부가적인 제약 함수\n",
    "\n",
    "입력값에 대해 활성화 함수로 시그모이드 함수를 사용하고, 출력 값으로 10개의 값을 출력하는 완전 연결 계층은 다음과 같이 정의하면 된다.\n",
    "\n",
    "10개의 노드를 가지는 은닉층이 있고 최종 출력 값은 2개의 노드가 있는 신경망 구조를 생각해보자.\n",
    "그렇다면 객체를 두개 생성해서 신경망을 만들 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c441b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "INPUT_SIZE = (20, 1)\n",
    "inputs = tf.keras.layers.Input(shape = INPUT_SIZE)\n",
    "hidden = tf.keras.layers.Dense(units = 10, activation = tf.nn.sigmoid)(inputs)\n",
    "output = tf.keras.layers.Dense(units = 2, activation = tf.nn.sigmoid)(hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba6e015",
   "metadata": {},
   "source": [
    "## tf.keras.layers.Dropout\n",
    "\n",
    "신경망 모델을 만들 때 생기는 여러 문제점 중 대표적인 문제점은 **과적합(overfitting)** 이다.\n",
    "과적합 문제는 정규화 방법을 사용해서 해결하는데, 그중 가장 대표적인 방법이 `Dropout(드롭아웃)`이다.\n",
    "텐서플로는 드롭아웃을 쉽게 모델에 적용할 수 있게 간단한 모듈을 제공하는데,\n",
    "이 모듈을 이용하면 특정 `keras.layers`의 입력값에 드롭아웃을 적용할 수 있다.\n",
    "사용법은 위의 dense 층을 만드는 방법과 유사하게 Dropout 객체를 생성해서 사용하면 된다.\n",
    "\n",
    "```python\n",
    "tf.keras.layers.Dropout(...)\n",
    "```\n",
    "\n",
    "드롭아웃을 적용할 입력값을 설정해야 한다.\n",
    "앞서 진행했던 것과 입력값을 설정하는 방법은 동일하다.\n",
    "\n",
    "```python\n",
    "# 방법 1\n",
    "dense = tf.keras.layers.Dropout(...)\n",
    "output = dense(input)\n",
    "# 방법 2\n",
    "output = tf.keras.layers.Dropout(...)(input)\n",
    "```\n",
    "\n",
    "```python\n",
    "__init__(\n",
    "    rate, noise_shape=None, seed=None, **kwargs\n",
    ")\n",
    "```\n",
    "- rate : 드롭아웃을 적용할 확률을 지정한다. 확률 값이므로 0~1 사이의 값을 받는다. 예를 들어 dropout=0.2로 지정하면 전체 입력값 중에서 20%를 0으로 만든다.\n",
    "- noise_shape : 정수형의 1D-tensor 값을 받는다. 여기서 받은 값은 shape을 뜻하는데, 이 값을 지정함으로써 특정 값만 드롭아웃을 적용할 수 있다. 예를 들면, 입력값이 이미지일 때 noise_shape을 지정하면 특정 채널에만 드롭아웃을 적용할 수 있다.\n",
    "- seed : 드롭아웃의 경우 지정된 확률 값을 바탕으로 무작위로 드롭아웃을 적용하는데, 이때 임의의 선택을 위한 시드 값을 의미한다. seeda 값은 정수형이며, 같은 seed 값을 가지는 드롭아웃의 경우 동일한 드롭아웃 결과를 만든다.\n",
    "\n",
    "드롭아웃을 적용하는 과정을 생각해보자.\n",
    "학습 데이터에 과적합되는 상황을 방지하기 위해 학습 시 특정 확률로 노드들의 값을 0으로 만든다.\n",
    "그리고 이러한 과정은 학습할 때만 적용되고 예측 혹은 테스트할 때는 적용되지 않아야 한다.\n",
    "케라스의 Dropout을 사용할 경우 이러한 부분이 자동으로 적용된다.\n",
    "드롭아웃을 적용하는 방법은 아래와 같이 적용시킬 값을 입력 값으로 넣어주면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e6ba2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "INPUT_SIZE = (20, 1)\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape = INPUT_SIZE)\n",
    "dropout = tf.keras.layers.Dropout(rate = 0.5)(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "420a7d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "INPUT_SIZE = (20, 1)\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=INPUT_SIZE)\n",
    "output = tf.keras.layers.Dense(units=10, activation=tf.nn.sigmoid)(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142a9ea3",
   "metadata": {},
   "source": [
    "텐서플로에서 드롭아웃은 `tf.keras.layers`뿐만 아니라 `tf.nn`에도 있는데,\n",
    "두 모델의 차이점은 `tf.keras.layers.Dropout`의 경우 확률을 0.2로 지정했을 때 노드의 20%를 0으로 만드는 데 비해\n",
    "`tf.nn.Dropout`의 경우 확률을 0.2로 지정했을 때 80% 값을 0으로 만든다는 것이다.\n",
    "\n",
    "함수를 사용하는 방법을 알아보자.\n",
    "이전의 Dense 층 예제인 신경망 구조에서 처음 입력 값에 드롭아웃을 적용해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93e38435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "INPUT_SIZE = (20, 1)\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=INPUT_SIZE)\n",
    "dropput = tf.keras.layers.Dropout(rate=0.2)(inputs)\n",
    "hidden = tf.keras.layers.Dense(units=10, activation=tf.nn.sigmoid)(dropput)\n",
    "output = tf.keras.layers.Dense(units=2, activation=tf.nn.sigmoid)(hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8216f6",
   "metadata": {},
   "source": [
    "## tf.keras.layers.Conv1D\n",
    "\n",
    "이번에는 합성곱 연산 중 `Conv1D`에 대해서 알아보자.\n",
    "텐서플로의 합성곱 연산은 `Conv1D`, `Conv2D`, `Conv3D`로 나뉘어지는데 우선 이 세개가 어떤 차이점이 잇는지 알아보자.\n",
    "\n",
    "|-|합성곱의 방향|출력값|\n",
    "|-|-|-|\n",
    "|Conv1D|한 방향(가로)|1-D Array(Vector)|\n",
    "|Conv2D|두 방향(가로, 세로)|2-D Array(matrix)|\n",
    "|Conv3D|세 방향(가로, 세로, 높이)|3-D Array(tensor)|\n",
    "\n",
    "위의 표에서 나온 출력값의 경우 실제 합성곱 출력값과 동일하진 않다.\n",
    "배치 크기와 합성곱이 적용되는 필터의 개수도 고려해야 하기 때문에 출력값이 위와 동일하게 나오지 않는 것이다.\n",
    "위의 경우 단순히 배치의 경우, 고려하지 않고 합성곱 필터를 하나만 적용했을 때라고 생각하면 된다.\n",
    "\n",
    "<img src=\"conv1d.png\" alt=\"conv1d\" style=\"width: 300px;\"/>\n",
    "\n",
    "그림을 보면 빨간색 사격형이 하나의 필터가 된다.\n",
    "이 필터가 가로 방향으로만 옮겨가면서 입력값에 대해 합성곱을 수행한다. 연산 결과들이 모여서 최종 출력 값이 나온다.\n",
    "따라서 출력 값은 하단에 위치한 것과 같은 1차원 벡터가 된다.\n",
    "\n",
    "자연어 처리 분야에서 사용하는 합성곱의 경우 각 단어 벡터의 차원 전체에 대해 필터를 적용시기키 위해 주로 `Conv1D`를 사용한다.\n",
    "\n",
    "```python\n",
    "# 방법 1\n",
    "conv1d = tf.keras.layers.Conv1D(...)\n",
    "output = conv1d(input)\n",
    "\n",
    "# 방법 2\n",
    "output = tf.keras.layers.Conv1D(input)\n",
    "```\n",
    "\n",
    "```python\n",
    "__init__(\n",
    "    filters, kernel_size, strides=1, padding='valid',\n",
    "    data_format='channels_last', dilation_rate=1, groups=1,\n",
    "    activation=None, use_bias=True, kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros', kernel_regularizer=None,\n",
    "    bias_regularizer=None, activity_regularizer=None, kernel_constraint=None,\n",
    "    bias_constraint=None, **kwargs\n",
    ")\n",
    "```\n",
    "\n",
    "- filters : 필터의 개수로서, 정수형으로 지정한다. 출력의 차원 수를 나타낸다.\n",
    "- kernel_size : 필터의 크기로서, 정수 혹은 정수의 리스트, 튜플 형태로 지정한다. 합성곱이 적용되는 윈도의 길이를 나타낸다.\n",
    "- strides : 적용할 스트라이드의 값으로서 정수 혹은 정수의 리스트, 튜플 형태로 지정한다. 1이 아닌 값을 지정할 경우 dilation_rate는 1 이외의 값을 지정하지 못한다.\n",
    "- padding : 패딩 방법을 정한다. \"VALID\" 또는 \"SAME\"을 지정할 수 있다.\n",
    "- data_format : 데이터의 표현 방법을 선택한다. \"channel_last\" 혹은 \"channel_first\"를 지정할 수 있다. channel_list의 경우 데이터는(batch, length, channels) 형태여야 하고, channel_first의 경우 데이터는 (batch, channels, length) 형태여야 한다.\n",
    "- dilation_rate : dilation 합성곱 사용 시 적용할 dilation 값으로서 정수 혹은 정수의 리스트, 튜플 형태로 지정한다. 1이 아닌 값을 지정하면 strides 값으로 1이외의 값을 지정하지 못한다.\n",
    "- groups : 채널 축을 따라 입력이 분할되는 그룹 수를 지정하는 양의 정수입니다. 각 그룹은 필터/그룹 필터와 별도로 결합됩니다. 출력은 채널 축을 따라 모든 그룹 결과를 연결한 것입니다. 입력 채널과 필터는 모두 그룹으로 나눌 수 있어야 합니다.\n",
    "- activation : 활성화 함수\n",
    "- use_bias : 편향을 사용할지 여부.\n",
    "- kernel_initializer : 가중치 초기화 함수\n",
    "- bias_initializer : 편향 초기화 함수\n",
    "- kernel_regularizer : 가중치 정규화 방법\n",
    "- bias_regularizer : 편향 정규화 방법\n",
    "- activity_regularizer : 출력 값 정규화 방법\n",
    "- kernel_constraint : Optimizer에 의해 업데이트 된 이후에 가중치에 적용되는 부가적인 제약 함수\n",
    "- bias_constraint : Optimizer에 의해 업데이트 된 이후에 편향에 적용되는 부가적인 제약 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20a8ce91",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = (1, 28, 28)\n",
    "\n",
    "inputs = tf.keras.Input(shape=INPUT_SIZE)\n",
    "conv = tf.keras.layers.Conv1D(\n",
    "    filters=10,\n",
    "    kernel_size=3,\n",
    "    padding='same',\n",
    "    activation=tf.nn.relu\n",
    ")(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "453b40dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = (1, 28, 28)\n",
    "\n",
    "inputs = tf.keras.Input(shape=INPUT_SIZE)\n",
    "dropout = tf.keras.layers.Dropout(rate=0.2)(inputs)\n",
    "conv = tf.keras.layers.Conv1D(\n",
    "    filters=10,\n",
    "    kernel_size=3,\n",
    "    padding='same',\n",
    "    activation=tf.nn.relu\n",
    ")(dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7723e6f",
   "metadata": {},
   "source": [
    "## tf.keras.layers.MaxPool1D\n",
    "\n",
    "합성곱 신경망과 함께 쓰이는 기법 중 하나는 풀링이다.\n",
    "보통 피처 맵의 크기를 줄이거나 주요한 특징을 뽑아내기 위해 합성곱 이후에 적용되는 기법이다.\n",
    "풀링에는 주로 두 가지 풀링 기법이 사용되는데, 맥스 풀링과 평균 풀링이 있다.\n",
    "맥스 풀링은 피처 맵에 대해 최댓값만을 뽑아내는 방식이고,\n",
    "평균 풀링은 피처 맵에 대해 전체 값들을 평균한 값을 뽑는 방식이다.\n",
    "\n",
    "맥스 풀링도 합성곱과 같이 세가지 형태로 모델이 구분돼 있다.\n",
    "MaxPool1D, MaxPool2D, MaxPool3D로 나눠져 있는데 합성곱과 똑같은 원리다.\n",
    "자연어 처리에 주로 사용되는 합성곱과 동일하게 MaxPool1D를 주로 사용하는데 한 방향으로만 풀링이 진행된다.\n",
    "사용법은 앞에서 설명한 합성곱과 동일한다.\n",
    "\n",
    "```python\n",
    "# 방법 1\n",
    "max_pool = tf.keras.layers.MaxPool1D(...)\n",
    "max_pool.apply(input)\n",
    "\n",
    "# 방법 2\n",
    "max_pool = tf.keras.layers.MaxPool1D(...)(input)\n",
    "```\n",
    "\n",
    "```python\n",
    "__init__(\n",
    "    pool_size=2, strides=None, padding='valid',\n",
    "    data_format='channels_last', **kwargs\n",
    ")\n",
    "```\n",
    "\n",
    "- pool_size : 풀링을 적용할 필터의 크기를 뜻한다. 정수값을 받는다.\n",
    "- strides : 적용할 스트라이드의 값. 정수 혹은 None 값을 받는다.\n",
    "- padding : 패딩 방법을 지정한다. \"valid\" 또는 \"same\"을 지정할 수 있다.\n",
    "- data_format : 데이터의 표현 방법을 선택한다. \"channel_list\" 혹은 \"channel_first\"를 지정할 수 있다. channel_list의 경우 데이터는 (batch, length, channels) 형태여야 하고, channel_first의 경우 데이터는 (batch, length, channels) 형태여야 한다.\n",
    "\n",
    "입력값이 합성곱과 맥스 풀링을 사용한 후 완전 연결 계층을 통해 최정 출력 값이 나오는 구조를 만들어 보자.\n",
    "그리고 입력값에는 드롭아웃을 적용한다.\n",
    "그리고 맥스 풀링 결과값을 완전 연결 계층으로 연결하기 위해서는 행렬이었던 것을 벡터로 만들어야 한다.\n",
    "이때 `tf.keras.layers.Flatten`을 사용한다. Flatten의 경우 별다른 인자값 설정 없이도 사용할 수 있기 때문에 쉽게 사용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42d91797",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = (1, 28, 28)\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=INPUT_SIZE)\n",
    "dropout = tf.keras.layers.Dropout(rate=0.2)(inputs)\n",
    "conv = tf.keras.layers.Conv1D(\n",
    "         filters=10,\n",
    "         kernel_size=3,\n",
    "         padding='same',\n",
    "         activation=tf.nn.relu)(dropout)\n",
    "\n",
    "max_pool = tf.keras.layers.MaxPool2D(pool_size=3, padding='same')(conv)\n",
    "flatten = tf.keras.layers.Flatten()(max_pool)\n",
    "hidden = tf.keras.layers.Dense(units=50, activation=tf.nn.relu)(flatten)\n",
    "output = tf.keras.layers.Dense(units=10, activation=tf.nn.softmax)(hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaec8a98",
   "metadata": {},
   "source": [
    "## Sequential API\n",
    "\n",
    "`tf.keras.Sequential`은 케라스를 활용해 모델을 구축할 수 있는 가장 간단한 형태의 API이다.\n",
    "`Sequential` 모듈을 이용하면 간단한 순차적인 레이어의 스택을 구현할 수 있다.\n",
    "간단한 형태의 완전 연결 계층을 구현해보겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d04bcf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801bfef6",
   "metadata": {},
   "source": [
    "`Sequential` 인스턴스를 생성한 후 해당 인스턴스에 여러 레이어를 순차적으로 더하기만 하면 모델이 완성된다.\n",
    "이렇게 만든 모델을 입력값을 더한 순서에 맞게 레이어들을 통과시킨 후 최종 출력값을 뽑아오게 된다.\n",
    "`Sequential` 모듈의 경우 위와 같이 구현 자체가 매우 간단하다는 사실을 알 수 있다.\n",
    "그에 반해 모델 구현에 제약이 있는데, 모델의 층들이 순차적으로 구성돼 있지 않은 경우에는 `Sequential` 모듈을 사용해 구현하기가 어려울 수 있다.\n",
    "예를 들면, VQA(Visual Question Answering) 문제(사진과 질문이 입력값으로 주어지고 사진을 참고해 질문에 답하는 문제)의 경우 사진 데이터에서 특징을 뽑는 레이어와 질문 텍스트 데이터에서 특징을 뽑는 두 레이어가 각기 순차적으로 존재한다.\n",
    "따라서 최종적으로 출력값을 뽑기 위해서는 이 두 값을 합쳐야 하는데, 이러한 구조의 모델을 구현할 때 `Sequential`모듈을 사용하게 되면 하나의 플로만 계산할 수 있는 `Sequential` 모듈로는 두 개의 값을 합칠 수가 없기 때문에 여러 제약이 존재한다.\n",
    "따라서 이러한 경우에는 앞으로 소개할 다른 방법을 이용해 모델을 구현하는 것이 적절하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df23467",
   "metadata": {},
   "source": [
    "## Functional API\n",
    "\n",
    "`Sequential` 모듈은 간단한 레이어들의 스택 구조에는 적합하지만 복잡한 모델의 경우에는 여러 구현상의 제약이 있을 수 있다.\n",
    "예를 들면, 모델의 구조가 다음과 같을 경우 `Sequential` 모듈을 사용하기가 어려울 수 있다.\n",
    "- 다중 입력값 모델\n",
    "- 다중 출력값 모델\n",
    "- 공유 층을 활용하는 모델\n",
    "- 데이터 흐름이 순차적이지 않은 모델\n",
    "\n",
    "이러한 모델을 구현할 때는 케라의 `Functional API`를 사용하거나 이후 살펴볼 `Subclassing` 방식을 사용하는 것이 적절할 수 있다.\n",
    "`Functional API`를 활용해 앞에서 정의한 모델과 동일한 모델을 만들어 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9022e090",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = tf.keras.Input(shape=(32,))\n",
    "x = layers.Dense(64, activation='relu')(inputs)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "predictions = layers.Dense(10,  activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8681a418",
   "metadata": {},
   "source": [
    "`Functional API`를 활요하기 위해서는 입력값을 받는 Input 모듈을 선언해야 한다.\n",
    "이 모듈을 선언할 때는 모델의 입력으로 받는 값의 형태를 정의하면 된다.\n",
    "이 Input 모듈을 정의한 후 입력값을 적용할 레이어를 호출할 때 인자로 전달하는 방식으로 구현하면 된다.\n",
    "\n",
    "이처럼 정의한 후 최종 출력값을 사용해 모델을 학습하면 된다.\n",
    "그러면 마지막 출력값이 앞에서 `Sequential`로 구현했을 때의 모델과 동일한 형태가 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46993133",
   "metadata": {},
   "source": [
    "## Custom Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771957ad",
   "metadata": {},
   "source": [
    "앞에 두 API를 사용하기 위해 케라스는 `layers` 패키지에 정의된 레이어를 사용해 구현했다.\n",
    "대부분 구현하고자 하는 모델의 경우 해당 패키지에 구현돼 있지만\n",
    "새로운 연산을 하는 레이어 혹은 편의를 위해 여러 레이어를 하나로 묶은 레이어를 구현해야 하는 경우가 있다.\n",
    "이때 사용자 정의 층을 만들어 사용하면 된다.\n",
    "앞에서 정의한 모델에서는 dense 층이 여러 번 사용된 신경망을 사용했다.\n",
    "이 신경망을 하나의 레이어로 묶어 재사용성을 높이고 싶다면 다음과 같이 사용자 정의 층으로 정의하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb278814",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "class CustomLayer(layers.Layer):\n",
    "    def __init__(self, hidden_dimension, hidden_dimension2, output_dimension):\n",
    "        self.hidden_dimension = hidden_dimension\n",
    "        self.hidden_dimension2 = hidden_dimension2\n",
    "        self.output_dimension = output_dimension\n",
    "        super(CustomLayer, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.dense_layer1 = layers.Dense(self.hidden_dimension, activation='relu')\n",
    "        self.dense_layer2 = layers.Dense(self.hidden_dimension2, activation='relu')\n",
    "        self.dense_layer3 = layers.Dense(self.output_dimension, activation='softmax')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense_layer1(inputs)\n",
    "        x = self.dense_layer2(x)\n",
    "        return self.dense_layer3(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05fa931",
   "metadata": {},
   "source": [
    "사용자 정의 층을 정의할 때는 `layers` 패키지의 Layer 클래스를 상속받고 위와 같이 3개의 메소드를 정의하면 된다.\n",
    "우선 하이퍼파라미터는 객체를 생성할 때 호출되도록 `__init__` 메소드에서 정의하고,\n",
    "모델의 가중치와 관련된 값은 `build` 메소드에서 생성되도록 정의한다.\n",
    "그리고 이렇게 정의한 값들을 이용해 `call` 메소드에서 해당 층의 로직을 정의하면 된다.\n",
    "이렇게 정의한 사용자 정의 층은 `Sequential API` 나 `Functional API`를 활용할 때 하나의 층으로 사용할 수 있다.\n",
    "만약 `Sequentail` 모듈을 활용한다면 다음과 같이 사용하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71828668",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(CustomLayer(64, 64, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33737da3",
   "metadata": {},
   "source": [
    "## Subclassing (Custom Model)\n",
    "\n",
    "이번에는 가장 자유도가 높은 `Subclassing`을 알아보자.\n",
    "이 경우 `tf.keras.Model`을 상속받고 모델 내부 연산들을 직접 구현하면 된다.\n",
    "모델 클래스를 구현할 때는 객체를 생성할 때 호출되는 `__init__` 메소드와\n",
    "생성된 인스턴스를 호출할 때를 구현할 때(즉, 모델 연산이 사용될 때) 호출되는 `call` 메소드만 구현하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79b61609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, hidden_dimenstion, hidden_dimenstion2, output_dimension):\n",
    "        super(MyModel, self).__init__(name='my model')\n",
    "        self.dense_layer1 = layers.Dense(hidden_dimenstion, activation='relu')\n",
    "        self.dense_layer1 = layers.Dense(hidden_dimenstion2, activation='relu')\n",
    "        self.dense_layer3 = layers.Dense(output_dimension, activation='softmax')\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.dense_layer1(inputs)\n",
    "        x = self.dense_layer2(x)\n",
    "        return self.dense_layer3(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7e966a",
   "metadata": {},
   "source": [
    "구현 방법은 사용자 정의 층을 만드는 방식과 매우 유사하다.\n",
    "그뿐만 아니라 이 방법은 파이토치 프레임워크에서 모델을 구현할 때 사용하는 방식과도 매우 유사하다.\n",
    "`__init__` 메소드에서는 모델에 사용될 층과 변수를 정의하면 되고,\n",
    "`call` 메소드에서는 이렇게 정의한 내용을 활용해 모델 연산을 진행하면 된다.\n",
    "참고로 모델에서 사용될 층을 정의할 때도 사용자 정의 층을 사용할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351bccbc",
   "metadata": {},
   "source": [
    "## 모델 학습\n",
    "\n",
    "이제 모델 학습에 대해서 알아보자.\n",
    "모델 학습이라고 하지만, 실제로는 학습뿐 아니라 모델 검증, 예측 등 여러 과정을 포함한다는 점을 알아두자.\n",
    "텐서플로 2.0 공식 가이드에서 모델 학습에 대해 권장하는 방법은 크게 두가지로 나뉜다.\n",
    "1. 케라스 모델의 내장 API를 활용하는 방법\n",
    "2. 학습, 검증, 예측 등 모든 과정을 `GradientTape` 객체를 활용해 직접 구현하는 방법\n",
    "\n",
    "첫번째 방법의 경우 대부분 케라스 모델의 메소드로 이미 구현돼 있어 간편하다는 큰 장점이 있고,\n",
    "두번째 방법의 경우 첫번째 방법과 비교했을 때 일일이 구현해야 한다는 단점이 있지만 좀 더 복잡한 로직을 유연하고\n",
    "자유롭게 구현할 수 있다는 장점이 있다.\n",
    "\n",
    "우리는 주로 첫번째 방법으로 공부할 예정이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0fa311",
   "metadata": {},
   "source": [
    "### 내장 API를 활용하는 방법\n",
    "\n",
    "이미 정의된 케라스의 모델 객체가 있다고 가정해보자.\n",
    "이 모델 객체는 케라스의 모델 객체이기 때문에 여러 메소드가 이미 내장돼 있다.\n",
    "따라서 내장 메소드를 간단히 사용하기만 하면 된다.\n",
    "먼저 해야 할 일은 학습 과정을 정의하는 것이다.\n",
    "즉, 학습 과정에서 사용될 손실 함수, 오티마이저, 평가에 사용될 지표 등을 정의하면 된다.\n",
    "\n",
    "```python\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=[tf.keras.mertics.Accuracy()]\n",
    ")\n",
    "```\n",
    "\n",
    "위와 같이 정의하면 학습을 실행할 모든 준비가 끝난다.\n",
    "참고로 옵티마이저, 손실 함수, 평가 지표 등은 객체 형식으로 지정해도 되고\n",
    "다음과 같이 문자열 형태로 지정해도 된다.\n",
    "\n",
    "```python\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "```\n",
    "\n",
    "이제 정의된 모델 객체를 대상으로 학습, 평가, 예측 메소드를 호출하면 정의한 값들을 활용해 학습이 진행된다.\n",
    "즉, 다음과 같이 `fit` 메소드를 호출하면 데이터들이 모델을 통과하며 학습이 진행된다.\n",
    "아울러 학습이 진행되면서 각 에폭당 모델의 성능(손실함수, 정확도) 등이 출력되는 것을 확인할 수 있다.\n",
    "\n",
    "```python\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=3\n",
    ")\n",
    "```\n",
    "\n",
    "학습 과정에 있어서 각 에폭마다 검증을 진행하는 것 또한 가능하다.\n",
    "`evaluate` 메소드를 사용해 검증할 수 있지만 매번 에폭을 호출해야 한다는 번거로움이 있다.\n",
    "따라서 에폭마다 검증 결과를 보기 위해서는 `fit` 함수에 검증 데이터를 추가로 넣으면 된다.\n",
    "\n",
    "```python\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=3,\n",
    "    validation_data=(x_val, y_val)\n",
    ")\n",
    "```\n",
    "\n",
    "이제 모델을 구축하는 과정과 학습하는 과정을 모두 알아봤다.\n",
    "이어서 간단한 더미 데이터를 활용해 감정 분석 문제를 해결해 보자,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2c63e3",
   "metadata": {},
   "source": [
    "### 더미 데이터를 활용한 감정 분석 모델링\n",
    "\n",
    "[출처](https://github.com/NLP-kr/tensorflow-ml-nlp-tf2/blob/master/2.NLP_PREP/2.1.2.tensorflow2.ipynb)\n",
    "\n",
    "이번에 구현할 모델은 심층 신경망 구조를 사용해 앞서 텍스트의 긍정/부정을 예측하는 감정 분석 모델이다.\n",
    "감정 분석 문제에 대한 자세한 내용은 이후에 다시 소개할 것이며, 모델에 적용할 데이터는 앞에서 정의한 테스트 데이터를 사용한다.\n",
    "모델의 자세한 구조는 다음과 같다.\n",
    "\n",
    "<img src=\"심층신경망.png\" alt=\"심층신경망\" style=\"width: 300px;\"/>\n",
    "\n",
    "우선 각 단어로 구성된 입력값은 임베딩된 벡터로 변형된다.\n",
    "이후 각 벡터를 평균해서 하나의 벡터로 만든다.\n",
    "이후에 하나의 은닉층을 거친 후 하나의 결괏값을 뽑는 구조다.\n",
    "마지막으로 나온 결괏값에 시그모이드 함수를 적용해 0과 1사이의 값을 구한다.\n",
    "\n",
    "모델에서 나온 임베딩 벡터 등과 같은 내용이 잘 이해되지 않더라도 대략적인 모델의 구조가 위와 같이 구성된다는 것만 이해하면 된다.\n",
    "이후 자세한 내용은 다음 장에서 알려주도록 하겠다.\n",
    "이번 절에서는 텐서플로 2.0버전에서 케라스를 이용해 모델을 구현하는 방법을 중심적으로 살펴보자.\n",
    "\n",
    "이제 본격적으로 모델을 구현해 보자.\n",
    "데이터는 이전 장에서 사용했던 텍스트 데이터를 그대로 사용하고, 동일하게 전처리 과정을 적용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdc32e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import preprocessing\n",
    "\n",
    "samples = [\n",
    "    '너 오늘 이뻐 보인다',\n",
    "    '나는 오늘 기분이 더러워',\n",
    "    '끝내주는데, 좋은 일이 있나봐',\n",
    "    '나 좋은 일이 생겼어',\n",
    "    '아 오늘 진짜 짜증나',\n",
    "    '환성적인데, 정말 좋은거 같아'\n",
    "]\n",
    "\n",
    "targets= [[1], [0], [1], [1], [0], [1]]\n",
    "tokenizer = preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(samples)\n",
    "sequences = tokenizer.texts_to_sequences(samples)\n",
    "\n",
    "\n",
    "input_sequences = np.array(sequences)\n",
    "labels = np.array(targets)\n",
    "\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82281d55",
   "metadata": {},
   "source": [
    "전처리 과정은 앞에서 다뤘기 때문에 설명은 생략한다.\n",
    "추가로 모델 구축 및 모델 학습에 필요한 변수를 정의해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d2ddc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "batch_size = 2\n",
    "num_epochs = 100\n",
    "vocab_size = len(word_index) + 1\n",
    "emb_size = 128\n",
    "hidden_dimension = 256\n",
    "output_dimension = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c509774",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Embedding(vocab_size, emb_size, input_length=4))\n",
    "model.add(layers.Lambda(lambda x: tf.reduce_mean(x, axis=1)))\n",
    "model.add(layers.Dense(hidden_dimension, activation='relu'))\n",
    "model.add(layers.Dense(output_dimension, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de57be91",
   "metadata": {},
   "source": [
    "`Sequential` 객체를 생성한 후 각 층을 추가하면 된다.\n",
    "혹은 객체 생성 시 안자로 사용할 층을 순차적으로 리스트로 만들어서 전달하는 방법으로도 위와 동일한 모델을 생성할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b3477ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    layers.Embedding(vocab_size, emb_size, input_length=4),\n",
    "    layers.Lambda(lambda x: tf.reduce_mean(x, axis=1)),\n",
    "    layers.Dense(hidden_dimension, activation='relu'),\n",
    "    layers.Dense(output_dimension, activation='sigmoid'),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5a0522",
   "metadata": {},
   "source": [
    "구현한 모델을 보면 입력값을 임베딩하는 Embedding 층을 모델에 추가했다.\n",
    "이후 임베딩 된 각 단어의 벡터를 평균하기 위해 람다 층을 사용한다.\n",
    "람다 층은 텐서플로 연산을 `Sequential API`와 `Funcational API`에 적용하기 위해 사용하는 방법이다.\n",
    "평균의 경우 하나의 층으로 정의돼 있지 않기 때문에 람다 층을 활용해 해당 층에 들어오는 입력값들을 평균한다.\n",
    "람다 층을 활용해 평균을 낸 후 하나의 은닉층을 통과한 후 최종 출력값을 뽑기 위해 두개의 Dense 층을 모델에 추가한다.\n",
    "이때 최종 출력값을 뽑은 Dense 층의 경우 0과 1사이의 확률값을 뽑기 위해 활성화 함수를 시그모이드 함수로 정의한다.\n",
    "\n",
    "이렇게 최종 출력 층까지 모델에 추가헀다면 모델이 모두 완성된 것이다.\n",
    "모델을 구축하는 과정이 모두 끝났으니 모델을 학습해보자.\n",
    "케라스 내장 API를 활용해 모델을 학습하기 위해서는 우선 모델을 컴파일하는 메소드를 통해 학습 과정을 정의한다.\n",
    "옵티마이저의 경우 아담 최적화 알고리즘을 사용하고, 학습은 이진 분류 문제이므로 이진 교차 엔트로피 손실함수를 사용한다.\n",
    "그리고 추가로 모델의 성능을 측정하기 위한 기준인 평가 지표를 정의하는데, 이진 분류의 평가 지표로 가장 널리 사용되는 정확도를 평가 지표로 정의한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9278313f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933867fe",
   "metadata": {},
   "source": [
    "이처럼 컴파일 메소드로 학습 과정을 정의했다면 케라스의 내장 API를 통해 학습할 준비가 모두 끝났다.\n",
    "이제 `fit` 메소드를 통해 학습을 진행해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d66e360e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 4, 128)            2688      \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 35,969\n",
      "Trainable params: 35,969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9310556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 830us/step - loss: 0.6918 - accuracy: 0.5833\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 847us/step - loss: 0.6756 - accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 775us/step - loss: 0.6592 - accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 701us/step - loss: 0.6426 - accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 682us/step - loss: 0.6273 - accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 680us/step - loss: 0.6016 - accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 659us/step - loss: 0.5766 - accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 817us/step - loss: 0.5421 - accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 994us/step - loss: 0.5235 - accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.4859 - accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 704us/step - loss: 0.4297 - accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 623us/step - loss: 0.3817 - accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 657us/step - loss: 0.3495 - accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 706us/step - loss: 0.2706 - accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.2537 - accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.1918 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 732us/step - loss: 0.1538 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 679us/step - loss: 0.1413 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 752us/step - loss: 0.1069 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 766us/step - loss: 0.0669 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0631 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0401 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 694us/step - loss: 0.0311 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 594us/step - loss: 0.0295 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 633us/step - loss: 0.0200 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 603us/step - loss: 0.0226 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0164 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0149 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 672us/step - loss: 0.0114 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 677us/step - loss: 0.0095 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 665us/step - loss: 0.0092 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 596us/step - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 953us/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 834us/step - loss: 0.0074 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 631us/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 578us/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 706us/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 926us/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 622us/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 611us/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 782us/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 880us/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 702us/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 585us/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 637us/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 618us/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 708us/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 862us/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 953us/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 803us/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 744us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 885us/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 630us/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 589us/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 571us/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 591us/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 624us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 841us/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 806us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 593us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 888us/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 739us/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 656us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 685us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 617us/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 638us/step - loss: 9.8049e-04 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 959us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 861us/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 9.2589e-04 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 826us/step - loss: 8.5807e-04 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 8.1232e-04 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 934us/step - loss: 7.4537e-04 - accuracy: 1.0000\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 773us/step - loss: 7.9028e-04 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 7.8823e-04 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 7.3965e-04 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 654us/step - loss: 5.9324e-04 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 537us/step - loss: 6.0902e-04 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 683us/step - loss: 7.4083e-04 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 7.0483e-04 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 6.6331e-04 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 680us/step - loss: 6.5676e-04 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 671us/step - loss: 6.6969e-04 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 835us/step - loss: 5.7091e-04 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 949us/step - loss: 6.7974e-04 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 6.5816e-04 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 746us/step - loss: 5.6410e-04 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 795us/step - loss: 5.7805e-04 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 987us/step - loss: 4.6186e-04 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 924us/step - loss: 5.9969e-04 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 749us/step - loss: 5.2654e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14325d9a0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(input_sequences, labels, epochs=num_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5326fe0",
   "metadata": {},
   "source": [
    "`fit` 메소드를 호출하면 학습 경과가 출력되는 것을 확인할 수 있다.\n",
    "에폭이 경과함에 따라 손실함수의 값과 정확도가 늘어나는 것을 확인할 수 있다.\n",
    "더미 데이터의 결과이기 때문에 의미 있는 수치는 아니지만 텐서플로 2.0의 표준 방법을 통해 학습이 정상적으로 돌아가도록 구현했다는 데 의미가 있다.\n",
    "\n",
    "이제 `Sequential API`가 아닌 `Functional API`, `Subclassing` 방법으로 동일한 모델을 구현해보고 학습해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a94a745",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = layers.Input(shape = (4, ))\n",
    "embed_output = layers.Embedding(vocab_size, emb_size)(inputs)\n",
    "pooled_output = tf.reduce_mean(embed_output, axis=1)\n",
    "hidden_layer = layers.Dense(hidden_dimension, activation='relu')(pooled_output)\n",
    "outputs = layers.Dense(output_dimension, activation='sigmoid')(hidden_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8bd773fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9813e367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 4, 128)            2688      \n",
      "_________________________________________________________________\n",
      "tf.math.reduce_mean (TFOpLam (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 35,969\n",
      "Trainable params: 35,969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7817aa4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 838us/step - loss: 0.6913 - accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 755us/step - loss: 0.6765 - accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.6597 - accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 881us/step - loss: 0.6422 - accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 731us/step - loss: 0.6222 - accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 626us/step - loss: 0.5941 - accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 773us/step - loss: 0.5872 - accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 734us/step - loss: 0.5507 - accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.5083 - accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.4475 - accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 707us/step - loss: 0.3991 - accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 741us/step - loss: 0.4126 - accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 914us/step - loss: 0.3267 - accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.2805 - accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 818us/step - loss: 0.2939 - accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 920us/step - loss: 0.2241 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 996us/step - loss: 0.1651 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 965us/step - loss: 0.1798 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 960us/step - loss: 0.1214 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 777us/step - loss: 0.0983 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0755 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0702 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0505 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 785us/step - loss: 0.0406 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 620us/step - loss: 0.0336 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 657us/step - loss: 0.0184 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0165 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 865us/step - loss: 0.0200 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 686us/step - loss: 0.0122 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 675us/step - loss: 0.0137 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 678us/step - loss: 0.0118 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 705us/step - loss: 0.0109 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0097 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 687us/step - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 629us/step - loss: 0.0084 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 667us/step - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 569us/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0068 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 777us/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 573us/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 628us/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 603us/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 607us/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 967us/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 601us/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 594us/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 594us/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 548us/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 652us/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 610us/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 623us/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 695us/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 644us/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 648us/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 574us/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 859us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 816us/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 641us/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 913us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 602us/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 594us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 893us/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 967us/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 845us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 659us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 651us/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 753us/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 806us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 703us/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 859us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 669us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 982us/step - loss: 8.8379e-04 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 9.8060e-04 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 901us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 969us/step - loss: 9.4981e-04 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 8.4492e-04 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 639us/step - loss: 9.1039e-04 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 6.8703e-04 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 9.8845e-04 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 7.1114e-04 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 978us/step - loss: 9.4303e-04 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 9.4402e-04 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 729us/step - loss: 6.6462e-04 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 653us/step - loss: 8.8486e-04 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 836us/step - loss: 8.3195e-04 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 607us/step - loss: 6.8879e-04 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 557us/step - loss: 7.0615e-04 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 855us/step - loss: 5.9456e-04 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 848us/step - loss: 6.4550e-04 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 711us/step - loss: 7.5166e-04 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 835us/step - loss: 6.5201e-04 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 632us/step - loss: 6.2371e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x147849be0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(input_sequences, labels, epochs=num_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1fe8df",
   "metadata": {},
   "source": [
    "앞에서 알아본 것처럼 `Funcational API`는 케라스의 입력층을 구현한 후 각 값을 다음 레이어들을 호출하면서 인자로 넣는 방식으로 구현하면 된다.\n",
    "구현 방법에서 차이가 있을 뿐 모델 연산 흐름이나 로직이 변경된 것은 아니므로 결과는 동일하게 나온다.\n",
    "다음은 `Subclassing` 방법으로 동일한 모델을 구현해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da62314c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embed_dimension, hidden_dimension, output_dimension):\n",
    "        super(CustomModel, self).__init__(name='my_model')\n",
    "        self.embedding = layers.Embedding(vocab_size, embed_dimension)\n",
    "        self.dense_layer = layers.Dense(hidden_dimension, activation='relu')\n",
    "        self.output_layer = layers.Dense(output_dimension, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.embedding(inputs)\n",
    "        x = tf.reduce_mean(x, axis=1)\n",
    "        x = self.dense_layer(x)\n",
    "        x = self.output_layer(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4540827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 773us/step - loss: 0.6943 - accuracy: 0.2708\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.6793 - accuracy: 0.7292\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 795us/step - loss: 0.6658 - accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 673us/step - loss: 0.6511 - accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 649us/step - loss: 0.6305 - accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 695us/step - loss: 0.6094 - accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 637us/step - loss: 0.5918 - accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.5581 - accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 630us/step - loss: 0.5323 - accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 768us/step - loss: 0.4998 - accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 643us/step - loss: 0.4485 - accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 646us/step - loss: 0.4022 - accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 623us/step - loss: 0.3564 - accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 813us/step - loss: 0.3006 - accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.2666 - accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 659us/step - loss: 0.2115 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 644us/step - loss: 0.1705 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 639us/step - loss: 0.1462 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 707us/step - loss: 0.0870 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0633 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0701 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 820us/step - loss: 0.0439 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 640us/step - loss: 0.0323 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 773us/step - loss: 0.0302 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 803us/step - loss: 0.0236 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 616us/step - loss: 0.0182 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 898us/step - loss: 0.0166 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 678us/step - loss: 0.0122 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 641us/step - loss: 0.0117 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 638us/step - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0097 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 856us/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 604us/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 700us/step - loss: 0.0060 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 556us/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 829us/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 776us/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 629us/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 568us/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 618us/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 643us/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 897us/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 856us/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 636us/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 671us/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 585us/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 902us/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 616us/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 735us/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 619us/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 596us/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 604us/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 579us/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 830us/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 647us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 559us/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 616us/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 624us/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 793us/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 574us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 638us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 496us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 537us/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 767us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 582us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 624us/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 661us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 729us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 908us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 910us/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 643us/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 9.3408e-04 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 790us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 9.3460e-04 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 8.4390e-04 - accuracy: 1.0000\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 768us/step - loss: 8.6267e-04 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 8.9839e-04 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 7.2101e-04 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 8.1597e-04 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 7.9999e-04 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 700us/step - loss: 7.2653e-04 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 730us/step - loss: 8.7773e-04 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 618us/step - loss: 6.8281e-04 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 653us/step - loss: 8.3549e-04 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 843us/step - loss: 6.8566e-04 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 525us/step - loss: 7.1120e-04 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 878us/step - loss: 7.6687e-04 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 847us/step - loss: 6.9209e-04 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 849us/step - loss: 7.3838e-04 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 812us/step - loss: 5.8695e-04 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 564us/step - loss: 7.1833e-04 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 996us/step - loss: 6.6271e-04 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 724us/step - loss: 6.3410e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14786e220>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CustomModel(vocab_size = vocab_size,\n",
    "            embed_dimension=emb_size,\n",
    "            hidden_dimension=hidden_dimension,\n",
    "            output_dimension=output_dimension)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(input_sequences, labels, epochs=num_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2c1031",
   "metadata": {},
   "source": [
    "### keras custom layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6aead704",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLayer(layers.Layer):\n",
    "\n",
    "    def __init__(self, hidden_dimension, output_dimension, **kwargs):\n",
    "        self.hidden_dimension = hidden_dimension\n",
    "        self.output_dimension = output_dimension\n",
    "        super(CustomLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.dense_layer1 = layers.Dense(self.hidden_dimension, activation = 'relu')\n",
    "        self.dense_layer2 = layers.Dense(self.output_dimension)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        hidden_output = self.dense_layer1(inputs)\n",
    "        return self.dense_layer2(hidden_output)\n",
    "\n",
    "    # Optional\n",
    "    def get_config(self):\n",
    "        base_config = super(CustomLayer, self).get_config()\n",
    "        base_config['hidden_dim'] = self.hidden_dimension\n",
    "        base_config['output_dim'] = self.output_dim\n",
    "        return base_config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e9ab241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 796us/step - loss: 0.6927 - accuracy: 0.5625\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 988us/step - loss: 0.6750 - accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 952us/step - loss: 0.6624 - accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 871us/step - loss: 0.6372 - accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 773us/step - loss: 0.6249 - accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 709us/step - loss: 0.6069 - accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5798 - accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 654us/step - loss: 0.5362 - accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.5178 - accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 674us/step - loss: 0.4785 - accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 680us/step - loss: 0.4291 - accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 862us/step - loss: 0.3913 - accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 919us/step - loss: 0.3050 - accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 856us/step - loss: 0.3042 - accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 705us/step - loss: 0.2902 - accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 679us/step - loss: 0.2131 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 799us/step - loss: 0.1662 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 837us/step - loss: 0.1741 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 992us/step - loss: 0.0978 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 713us/step - loss: 0.0699 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 649us/step - loss: 0.0760 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 753us/step - loss: 0.0425 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 761us/step - loss: 0.0468 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 820us/step - loss: 0.0257 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 845us/step - loss: 0.0324 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 682us/step - loss: 0.0243 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 672us/step - loss: 0.0211 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 811us/step - loss: 0.0171 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 744us/step - loss: 0.0142 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0113 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 674us/step - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 760us/step - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 620us/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 713us/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 999us/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 610us/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 605us/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 901us/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 636us/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 847us/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 882us/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 615us/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 650us/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 625us/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 583us/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 700us/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 903us/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 738us/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 588us/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 613us/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 658us/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 925us/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 629us/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 537us/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 653us/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 592us/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 617us/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 716us/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 841us/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 678us/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 543us/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 852us/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 763us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 590us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 543us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 726us/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 835us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 676us/step - loss: 9.5326e-04 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 926us/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 691us/step - loss: 9.5998e-04 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 686us/step - loss: 8.8931e-04 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 9.1760e-04 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 816us/step - loss: 9.6658e-04 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 8.8761e-04 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 672us/step - loss: 9.9351e-04 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 972us/step - loss: 8.7194e-04 - accuracy: 1.0000\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 929us/step - loss: 8.9408e-04 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 8.3963e-04 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 7.5857e-04 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 637us/step - loss: 7.0989e-04 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 771us/step - loss: 7.4960e-04 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 962us/step - loss: 7.8173e-04 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 631us/step - loss: 6.7608e-04 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 709us/step - loss: 6.3191e-04 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 679us/step - loss: 6.9969e-04 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 596us/step - loss: 6.2004e-04 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 832us/step - loss: 6.6587e-04 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 563us/step - loss: 6.9740e-04 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 566us/step - loss: 6.0152e-04 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 617us/step - loss: 5.0029e-04 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 951us/step - loss: 5.2985e-04 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 678us/step - loss: 6.5535e-04 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 602us/step - loss: 5.8881e-04 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 700us/step - loss: 5.6576e-04 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 646us/step - loss: 4.5775e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x165ba5eb0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    layers.Embedding(vocab_size, emb_size, input_length = 4),\n",
    "    layers.Lambda(lambda x: tf.reduce_mean(x, axis = 1)),\n",
    "    CustomLayer(hidden_dimension, output_dimension),\n",
    "    layers.Activation('sigmoid')])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(input_sequences, labels, epochs=num_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d79a7eb",
   "metadata": {},
   "source": [
    "# 사이킷런\n",
    "\n",
    "사이킷런은 파이썬용 머신러닝 라이브러리이다.\n",
    "머신러닝 기술을 활용하는 데 필요한 다양한 기능을 제공하며, 파이썬으로 머신러닝 모델을 만들 수 있는 최적의 라이브러리다.\n",
    "라이브러리를 구성하는 대부분의 모듈들이 통일된 인터페이스를 가지고 있어 간단하게 여러 기법을 적용할 수 있으며, 쉽고 빠르게 원하는 결과를 얻을 수 있다.\n",
    "\n",
    "딥러닝 모델을 텐서플로, 케라스, 파이토치 등을 이용해서 생성할 수 있는 것처럼 머신러닝 모델은 주로 사이킷런 라이브러리를 통해 만들어 낼 수 있다.\n",
    "사이킷런 라이브러리는 지도 학습을 위한 모듈, 비지도 학습을 위한 모듈, 모델 선택 및 평가를 위한 모듈,\n",
    "데이터 변환 및 데이터를 불러오기 위한 모듈, 계산 성능 향상을 위한 모듈로 구성돼 있다.\n",
    "\n",
    "지도 학습 모듈에는 나이브 베이즈, 의사결정 트리, 서포트 벡터 머신 모델 등이 있다.\n",
    "비지도 학습 모듈에는 군집화, 가우시안 혼합 모델 등이 있다.\n",
    "\n",
    "모델 선택과 평가 모듈에서는 교차 검증, 모델 평가, 모델의 지속성을 위해 모델 저장과 불러오기를 위한 기능 등을 제공한다.\n",
    "그리고 데이터 변환 모듈에서는 파이프라인, 특징 추출, 데이터 전처리, 차원 축소 등의 기능을 제공한다.\n",
    "\n",
    "또한 머신러닝 연구와 학습을 위해 라이브러리 안에 자체적으로 데이터 셋을 포함하고 있고, 이를 쉽게 불러와서 사용할 수 있다.\n",
    "라이브러리에서 기본적으로 제공되는 데이터로는 당뇨병 데이터, 아이리스 데이터, 유방암 데이터 등이 있다.\n",
    "\n",
    "머신러닝을 통해 문제를 해결하기 위해서는 해결해야 할 문제에 적합한 알고리즘을 선택하는 것이 매우 중요한데\n",
    "사이킷런에서 제공하는 아래의 그림을 참고하면 좀 더 쉽게 문제를 해결하는 데 적합한 모델을 선택할 수 있다.\n",
    "\n",
    "<img src=\"scikit_learn.png\" alt=\"scikit_learn\" style=\"width: 500px;\"/>\n",
    "\n",
    "이번 절에서는 전체적인 사이킷런의 사용법을 알아본다.\n",
    "먼저 지도 학습 모듈에 대해 알아본 후 비지도 학습 모듈에 대해 알아보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "faa1c9e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.24.2'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4192ae9c",
   "metadata": {},
   "source": [
    "## 데이터 소개\n",
    "\n",
    "각 모델을 사용해 보기 전에 우선은 공통적으로 사용할 데이터에 대해 알아보자.\n",
    "이번 절에서 사용할 데이터는 머신러닝 기초를 배울 때 흔히 사용되는 붓꽃 데이터이다.\n",
    "이 데이터는 1936년에 만들어진 데이터로서 매우 직관적이고 사용하기도 쉬워서 자주 사용된다.\n",
    "\n",
    "붓꽃 데이터는 사이킷런 라이브러리에 기본적으로 내장돼 있는 데이터 중 하나라서 따로 설치할 필요 없이 바로 사용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6aab2462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris_dataset key : dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_data = load_iris()\n",
    "print(\"iris_dataset key : {}\".format(iris_data.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cea450f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n",
      "shape of data: (150, 4)\n"
     ]
    }
   ],
   "source": [
    "print(iris_data['data'])\n",
    "print(\"shape of data: {}\".format(iris_data[\"data\"].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b1531e",
   "metadata": {},
   "source": [
    "data에는 실제 데이터가 포함돼 있다.\n",
    "각 데이터마다 4개의 특징 값을 가지고 있다.\n",
    "데이터의 형태를 보면 (150, 4)로 전체 150개의 데이터가 각각 4개의 특징값을 가지고 있는 형태다.\n",
    "4개의 특징값이 의미하는 바를 확인하기 위해 'feature_names' 값을 확인해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d54fb79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "print(iris_data['feature_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a7c1ca45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "print(iris_data['target'])\n",
    "print(iris_data['target_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "81de7934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "print(iris_data['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92efdfb",
   "metadata": {},
   "source": [
    "## 사이킷런을 이용한 데이터 분리\n",
    "\n",
    "사이킷런을 이용하면 학습 데이터를 대상으로 학습 데이터와 평가 데이터로 쉽게 나눌 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8752a28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "256ac50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, test_input, train_label, test_label = train_test_split(\n",
    "    iris_data['data'],\n",
    "    iris_data['target'],\n",
    "    test_size=0.25,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86a0411",
   "metadata": {},
   "source": [
    "`train_test_split` 함수를 사용하려면 우선 나누고 싶은 데이터를 넣는다.\n",
    "여기서는 데이터 값과 라벨인 타깃 값을 넣었다.\n",
    "그러고 나서 평가 데이터의 크기를 결정해야 한다.\n",
    "이 값의 경우 0과 1사이의 값을 넣어야 하는데, 이는 비율을 의미한다.\n",
    "즉, 0.25로 설정할 경우 전체 학습 데이터의 25%를 따로 나눠준다는 의미다.\n",
    "마지막으로 `random_state` 값을 설정한다.\n",
    "이 함수가 데이터를 나눌 때 무작위로 데이터를 선택해서 나누는데, 이때 무작위로 선택되는 것을 제어할 수 있는 값이 `random_state` 값이다.\n",
    "함수를 여러 번 사용하더라도 이 값을 똑같이 설정할 경우 동일한 데이터를 선택해서 분리할 것이다.\n",
    "이렇게 나눈 다음, 각 변수의 형태를 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d202471a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train_input: (112, 4)\n",
      "shape of test_input: (38, 4)\n",
      "shape of train_label: (112,)\n",
      "shape of test_label: (38,)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of train_input: {}\".format(train_input.shape))\n",
    "print(\"shape of test_input: {}\".format(test_input.shape))\n",
    "print(\"shape of train_label: {}\".format(train_label.shape))\n",
    "print(\"shape of test_label: {}\".format(test_label.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6e15c4",
   "metadata": {},
   "source": [
    "결과를 보면 학습 데이터가 총 112개이고, 평가 데이터가 38개다.\n",
    "앞에서 평가 데이터의 크기를 전체의 25%로 설정했기 때문에 150개의 25%에 해당하는 38개가 평가 데이터로 설정됐다.\n",
    "나머지 75%에 해당하는 112개의 데이터는 학습 데이터로 사용할 것이다.\n",
    "\n",
    "학습 데이터와 평가 데이터가 따로 존재하지 않는 경우에는 이처럼 학습 데이터의 일부분을 평가 데이터로 사용한다.\n",
    "평가 데이터가 있는 경우에도 이 함수를 사용해 학습 데이터의 일부분을 따로 분리해 놓는 경우가 있는데,\n",
    "이러한 경우는 학습 데이터를 학습 데이터와 검증 데이터로 구분하는 경우다.\n",
    "즉, 학습 데이터, 평가 데이터, 검증 데이터로 총 3개의 데이터로 나눈다.\n",
    "이 경우에는 우선 학습 데이터를 사용해서 모델을 학습시키고 학습시킨 모델에 대해 일차적으로 검증 데이터를 사용해 모델 검증을 진행한다.\n",
    "그 결과를 통해 모델의 하이퍼파라미터를 수정한다.\n",
    "이처럼 학습과 검증 과정을 반복적으로 진행한 후 최종적으로 나온 모델에 대해 평가 데이터를 사용해 평가한다.\n",
    "이러한 방식은 모델을 만드는 과정에서 대부분 사용하는 방법이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae7dd0f",
   "metadata": {},
   "source": [
    "## 사이킷런을 이용한 지도 학습\n",
    "\n",
    "사이킷런을 통해 지도 학습 모델을 만드는 방법을 알아보자.\n",
    "우선 지도 학습이란 각 데이터에 대해 정답이 있는 경우 각 데이터의 정답을 예측할 수 있게 학습시키는 과정이다.\n",
    "즉, 모델이 예측하는 결과를 각 데이터의 정답과 비교해서 모델을 반복적으로 학습시킨다.\n",
    "\n",
    "이번 절에서는 지도 학습 모델 중 하나를 선택해서 직접 사용해 보겠다.\n",
    "지도 학습 모델에는 다양한 모델이 있지만 간단하고 데이터 특성만 맞는다면 좋은 결과를 확인할 수 있는 k-최근접 이웃 분류기를 사용한다.\n",
    "k-최근접 이웃 분류기는 예측하고자 하는 데이터에 대해 가장 가까운 거리에 있는 데이터의 라벨과 같다고 예측하는 방법이다.\n",
    "**이 방법은 데이터에 대한 사전 지식이 없는 경우의 분류에 많이 사용된다.**\n",
    "\n",
    "여기서 k 값은 예측하고자 하는 데이터와 가까운 몇 개의 데이터를 참고할 것인지를 의미한다.\n",
    "즉, k 값이 1이라면 예측하고자 하는 데이터에서 가장 가까운 데이터 하나만 참고해서 그 데이터와 같은 라벨이라고 예측하거,\n",
    "k 값이 3인 경우는 예측하려는 데이터에서 가장 가까운 3개의 데이터를 참고해서 그 3개 데이터의 라벨 중 많은 라벨을 결과로 예측한다.\n",
    "아래 그림을 보고 k=1인 경우와 k=3인 경우를 구분 지어 이해해보자.\n",
    "\n",
    "<img src=\"kNeighborsClassifier.png\" alt=\"kNeighborsClassifier\" style=\"width: 500px;\"/>\n",
    "\n",
    "그림을 보면 k=1인 경우에는 가장 가까운 데이터의 라벨값이 Class1이기 때문에 Class1로 예측한다.\n",
    "k=3인 경우에는 가까운 3개의 데이터가 Class1 1개, Class2 2개로 구성돼 있기 때문에 이 경우에는 Class2로 예측하게 된다.\n",
    "\n",
    "이러한 K-최근접 이웃 분류기의 특징은 아래와 같다.\n",
    "\n",
    "- 데이터에 대한 가정이 없어 단순한다.\n",
    "- 다목적 분류와 회귀에 좋다.\n",
    "- 높은 메모리를 요구한다.\n",
    "- k값이 커지면 계산이 늦어질 수 있다.\n",
    "- 관련 없는 기능의 데이터의 규모에 민감하다.\n",
    "\n",
    "이제 이러한 k-최근접 이웃 분류기를 직접 만들어보자.\n",
    "우선 분류기 객체를 불러와 변수에 할당한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "76252401",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98ef61e",
   "metadata": {},
   "source": [
    "분류기를 생성할 때 인자 값으로는 `n_neighbors` 값을 받는데, 이 값은 위에서 설명한 k 값을 의미한다.\n",
    "즉, 여기서는 k=1인 분류기 생성한 것이다.\n",
    "이제 이렇게 생성한 분류기를 학습 데이터에 적용하면 되는데, 간단하게 아래와 같이 구현할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3521f9be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_jobs=1, n_neighbors=1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "knn.fit(train_input, train_label)\n",
    "KNeighborsClassifier(\n",
    "    algorithm='auto',\n",
    "    leaf_size=30,\n",
    "    metric='minkowski',\n",
    "    metric_params=None,\n",
    "    n_jobs=1,\n",
    "    n_neighbors=1,\n",
    "    p=2,\n",
    "    weights='uniform'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bda6ff",
   "metadata": {},
   "source": [
    "위와 같이 `fit` 함수를 사용해 분류기 모델에 학습 데이터와 라벨 값을 적용하기만 하면 모델 학습이 간단하게 끝난다.\n",
    "이제 학습시킨 모델을 사용해 새로운 데이터의 라벨을 예측해보자.\n",
    "우선은 새롭게 4개의 피처값을 임의로 설정해서 넘파이 배열로 만들자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "10ffbe7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "new_input = np.array([[6.1, 2.8, 4.7, 1.2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca50560",
   "metadata": {},
   "source": [
    "4개의 특징값을 직접 입력해서 넘파이 배열로 만들었다.\n",
    "생성한 배열을 보면 꽃받침 길이와 너비가 각각 6.1, 2.8이고 꽃잎의 길이와 너비가 각각 4.7, 1.2인 데이터로 구성돼 있다.\n",
    "참고로 배열을 생성할 때 리스트 안에 또 하나의 리스트가 포함된 방식으로 만들었는데,\n",
    "이렇게 생성하지 않고 하나의 리스트만 사용해서 정의한 경우 이를 함수에 적용하면 오류가 발생한다.\n",
    "\n",
    "이제 이 값을 대상으로 앞에서 만든 분류기 모델의 `predict` 함수를 사용해 결과를 예측해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ba0a0878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.predict(new_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00aa7388",
   "metadata": {},
   "source": [
    "보다시피 1(Versicolor)로 예측하고 있다.\n",
    "이 데이터는 임의로 만든 것이기 때문에 이 결과가 제대로 예측한 것인지 확인할 수 없다.\n",
    "이제 모델의 성능을 측정하기 위해 이전에 따로 분리해둔 평가 데이터를 사용해 모델의 성능을 측정해보자.\n",
    "우선 따로 분리해둔 평가 데이터에 대해 예측을 하고 그 결괏값을 변수에 저장하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6c98d468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0 0 0 1 0 0 2 1\n",
      " 0]\n"
     ]
    }
   ],
   "source": [
    "predict_label = knn.predict(test_input)\n",
    "print(predict_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08483c9f",
   "metadata": {},
   "source": [
    "이제 예측한 결과값과 실제 결괏값을 비교해서 정확도가 어느 정인지 측정해보자.\n",
    "실제 결과와 동일한 것의 개수를 평균을 구하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f7088ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 1.00\n"
     ]
    }
   ],
   "source": [
    "print('test accuracy {:.2f}'.format(np.mean(predict_label==test_label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f687ad5c",
   "metadata": {},
   "source": [
    "정확도가 1.00 인데, 전체 100%의 정확도로서 매우 좋은 성능을 보여준다.\n",
    "이것은 데이터 자체가 특징이 라벨에 따라 구분이 잘 되고 모델이 데이터에 매우 적합하다는 것을 의미한다.\n",
    "이제 비지도 학습 모델을 만드는 방법을 알아보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ddd9a1",
   "metadata": {},
   "source": [
    "## 사이킷런을 이용한 비지도 학습\n",
    "\n",
    "이전 장에서 지도 학습 모델을 사이킷런 라이브러리를 사용해 만드는 방법을 알아봤다.\n",
    "이번에는 사이킷런을 통해 비지도 학습 모델을 만들어 보자.\n",
    "비지도 학습이란 지도학습과는 달리 데이터에 대한 정답, 즉 라벨을 사용하지 않고 만들 수 있는 모델이다.\n",
    "모델을 통해 문제를 해결하고 싶은데 데이터에 대한 정답이 없는 경우에 적용하기에 적합한 모델이다.\n",
    "\n",
    "비지도 학습 방법에도 여러 가지 방법이 있지만 여기서는 군집화 방법 중 하나인 k-평균 군집화 모델을 사용해 진행한다.\n",
    "군집화란 데이터를 특성에 따라 여러 집단으로 나누는 방법이다.\n",
    "따라서 붓꽃 데이터의 경우에는 3개의 정답이 있으므로 3개의 군집단으로 나누는 방법을 사용해야 할 것이다.\n",
    "\n",
    "k-평균 군집화는 군집화 방법 중 가장 간단하고 널리 사용되는 군집화 방법이며, 데이터 안에서 대표하는 군집의 중심을 찾는 알고리즘이다.\n",
    "알고리즘은 계속해서 반복적으로 수행되는데, 우선 k개만큼의 중심을 임의로 설정한다.\n",
    "그러고 난 후, 모든 데이터를 가장 가까운 중심에 할당하며, 같은 중심에 할당된 데이터들을 하나의 군집으로 판단한다.\n",
    "각 군집 내 데이터들을 가지고 군집의 중심을 새로 구해서 업데이트 한다.\n",
    "이후 또 다시 가까운 중심에 할당되고 이러한 과정이 계속 반복된다.\n",
    "이러한 반복은 할당되는 데이터에 변화가 없을 때까지 이뤄진다.\n",
    "이후 반복이 종료되면 각 데이터가 마지막으로 할당된 중심에 따라 군집이 나뉜다.\n",
    "붓꽃 데이터를 군집화한다면 다음 그림처럼 각 붓꽃 데이트들은 각 군집으로 나뉠 것이다.\n",
    "\n",
    "<img src=\"https://t1.daumcdn.net/cfile/tistory/9945D2375F433D4305\" alt=\"k-평균 군집화\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a37a129e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "k_means = KMeans(n_clusters=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef0137c",
   "metadata": {},
   "source": [
    "앞서 사용했던 k-최근접 이웃 분류기 보델과 비슷하다.\n",
    "우선 군집화 모듈에서 KMeans를 불러온 후 k-평균 군집화 모델을 만들면 된다.\n",
    "이때 인자로 k값을 의미하는 군집의 개수를 설정한다.\n",
    "여기서는 3개의 군집을 만들어야 하기 때문에 이 값을 3으로 설정한다.\n",
    "이제 군집화 모델에 데이터를 적용하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "03c587e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=3)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_means.fit(train_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e6e936",
   "metadata": {},
   "source": [
    "이전과 같이 `fit` 함수를 사용해 데이터와 라벨을 입력하면 자동으로 데이터를 군집화한다.\n",
    "하지만 앞서 진행한 지도 학습 모델과는 다른 점이 있는데, `fit` 함수의 인자로 데이터의 라벨값을 넣지 않았다.\n",
    "비지도 학습 모델인 k-평균 군집화는 라벨을 필요로 하지 않고 입력 데이터만을 사용해서 비슷한 데이터끼리 군집을 만들기 때문에 라벨을 넣지 않아도 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1a48c458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1, 0, 0, 1, 1, 2, 1, 2, 1, 2, 1, 0, 2, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 1, 2, 0, 1, 1, 0, 1, 1, 1, 1, 2, 1, 0, 1, 2, 0,\n",
       "       0, 1, 2, 0, 1, 0, 0, 1, 1, 2, 1, 2, 2, 1, 0, 0, 1, 2, 0, 0, 0, 1,\n",
       "       2, 0, 2, 2, 0, 1, 1, 1, 2, 2, 0, 2, 1, 2, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       2, 2, 0, 1, 2, 2, 0, 2, 0, 2, 2, 2, 1, 2, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 2], dtype=int32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_means.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945557ab",
   "metadata": {},
   "source": [
    "앞선 설명에 따르면 붓꽃의 라벨을 확인할 수 없다고 했는데, 각 데이터에 라벨링이 돼 있다.\n",
    "이것은 사실 붓꽃의 라벨을 의미하는 것이 아니라 3개의 군집으로 k-평균 군집화한 각 군집을 나타낸다.\n",
    "즉, `k_means.labels_`에 나온 0이라는 라벨은 0번째 군집을 의미하고, 붓꽃 데이터의 라벨 0은 Setosa 종을 의미한다.\n",
    "\n",
    "따라서 각 군집의 붓꽃 종의 분포를 확인하기 위해 다음과 같이 작성해서 각 군집의 종을 확인해 보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "021240dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cluster: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "1 cluster: [2 1 1 1 2 1 1 1 1 1 2 1 1 1 2 2 2 1 1 1 1 1 2 1 1 1 1 2 1 1 1 2 1 1 1 1 1\n",
      " 1 1 1 1 1 1 2 2 1 2 1]\n",
      "2 cluster: [2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 1 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(\"0 cluster:\", train_label[k_means.labels_ == 0])\n",
    "print(\"1 cluster:\", train_label[k_means.labels_ == 1])\n",
    "print(\"2 cluster:\", train_label[k_means.labels_ == 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fc1a29",
   "metadata": {},
   "source": [
    "결과를 보면 0번째 군집은 라벨 1인 데이터들이 주로 분포돼 있고, 1번째 군집은 라베 0인 데이터들만 분포돼 있다.\n",
    "따라서 새로운 데이터에 대해서 0번째 군집으로 예측할 경우 라벨 2로, 1번째 군집으로 예측할 경우 라벨 0으로,\n",
    "2번째 군집으로 예측할 경우 라벨 1로 판단할 수 있다.\n",
    "\n",
    "하지만 여기서 중요한 것은 항상 결과가 위와 동일하게 나오지 않고 군집화를 진행할 때마다 바뀐다는 것이다.\n",
    "즉, 0번째 군집에 라벨인 데이터들이 주로 분포할 수도 있다.\n",
    "이는 k-평균 군집화 모델 알고리즘 특성 때문에 불가피하게 발생하는 현상이다.\n",
    "k-평균 군집화의 경우 처음에 초기값을 랜덤으로 설정한 후 군집화 과정을 진행하는데 이러한 과정 때문에 군집의 순서가 바뀔 수도 있다.\n",
    "따라서 위의 코드를 실행할 때 책과 다른게 결과가 나오더라도 잘못 된 것이 아니고, 각 군집이 어떤 라벨을 의미하는지만 파악하면 된다.\n",
    "\n",
    "앞서 지도 학습에서 진행했던 것과 동일하게 임의의 새로운 데이터를 만들어서 예측을 진행해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2cb46041",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "new_input = np.array([[6.1, 2.8, 4.7, 1.2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f4ce9d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "prediction = k_means.predict(new_input)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309b1680",
   "metadata": {},
   "source": [
    "결과를 보면 새롭게 정의한 데이터는 2번째 군집에 포함된다고 예측했다.\n",
    "앞서 확인했을 때 0번째 군집은 주로 라벨 2인 종의 붓꽃들이 군집화돼 있었기 때문에 새로운 데이터 역시 라벨 2로 예측할 수 있을 것이다.\n",
    "마지막으로 해당 모델의 성능을 측정하기 위해 평가 데이터를 적용시켜서 실제 라벨과 비교해 성능을 측정해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c4122076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 1 0 2 2 2 2 2 0 0 0 0 1 0 0 1 1\n",
      " 0]\n"
     ]
    }
   ],
   "source": [
    "predict_cluster = k_means.predict(test_input)\n",
    "print(predict_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b06ea7",
   "metadata": {},
   "source": [
    "평가 데이터를 적용시켜 예측한 군집을 이제 각 붓꽃의 종을 의미하는 라벨 값으로 다시 바꿔줘야 실제 라벨과 비교해서 성능을 측정할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0a89727b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 0, 0, 2, 0, 1, 0, 0, 1, 2, 2, 2, 2, 0, 1, 0, 0, 1, 2, 0, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 0, 2, 2, 0, 0, 2]\n"
     ]
    }
   ],
   "source": [
    "np_arr = np.array(predict_cluster)\n",
    "np_arr[np_arr==0], np_arr[np_arr==1], np_arr[np_arr==2] = 3, 4, 5\n",
    "np_arr[np_arr==3] = 2\n",
    "np_arr[np_arr==4] = 0\n",
    "np_arr[np_arr==5] = 1\n",
    "predict_label = np_arr.tolist()\n",
    "print(predict_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cb8867",
   "metadata": {},
   "source": [
    "각 데이터가 속한 군집의 순서를 실제 붓꽃의 라벨로 바꿔주었다.\n",
    "만약 각 군집의 라벨 분포가 다르게 나온다면 각 군집이 어떤 라벨을 의미하는지 파악한 후 해당 라벨로 바꿔줘야 한다.\n",
    "여기서는 0번째 군집이 라벨 2, 1번째 군집이 라벨 0, 2번째 군집이 라벨 1를 의미한다.\n",
    "이를 변경할 때는 임시 저장을 위해 군집의 순서값 3,4,5를 넘파이 배열로 먼저 만들어 준다.\n",
    "이후 군집 3을 2로, 군집 4를 0으로, 군집 5를 1로 바꿔주었다.\n",
    "\n",
    "이제 모델 성능을 측정하기 위해 각 평가 데이터에 대해 예측값을 모두 구했다.\n",
    "실제 라벨과 비교해서 성능이 어느 정도 되는지 확인해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6d4f239d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.00\n"
     ]
    }
   ],
   "source": [
    "print('test accuracy {:.2f}'.format(np.mean(predict_label == test_label)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5f5752",
   "metadata": {},
   "source": [
    "결과를 보면 앞서 진행한 지도 학습 모델보다는 낮은 성능이지만 그래도 95%라는 매우 높은 성능을 보여준다.\n",
    "데이터의 라벨을 사용하지 않고 학습했음에도 불구하고 이 정도의 성능이면 매우 우수한 결과다.\n",
    "따라서 만약 데이터는 있지만 각 데이터의 라벨이 존재하지 않을 때는 비지도 학습 모델을 쓰는 것도 나쁘지 않은 방법이다.\n",
    "\n",
    "이렇게 해서 붓꽃 데이터와 사이킷런 라이브러리를 활용해 지도 학습 모델과 비지도 학습 모델을 사용하는 방법을 알아봤다.\n",
    "사이킷런 라이브러리 내의 함수들은 사용하기가 아주 쉽게 구성돼 있어 데이터를 적용하기만 하면 자동으로 학습과 예측을 수행했는데,\n",
    "만약 데이터가 붓꽃 데이터와는 다르게 수치형 데이터가 아닐 경우에는 어떻게 해야 할까?\n",
    "예를 들어, 인간 언어의 경우 수치화돼 있지 않은 데이터이기 때문에 다양한 머신러닝 모델에 바로 적용할 수 없다.\n",
    "이어지는 절에서는 이러한 상황을 해결하기 위한 특징 추출 모듈에 대해 알아보겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55db1ef9",
   "metadata": {},
   "source": [
    "## 사이킷런을 이용한 특징 추출\n",
    "\n",
    "이번 절에서는 사이킷런의 특징 추출 모듈에 대해 알아보겠다.\n",
    "자연어 처리에서 특징 추출이란 텍스트 데이터에서 단어나 문장들을 어떤 특징 값으로 바꿔주는 것을 의미한다.\n",
    "기존에 문자로 구성돼 있던 데이터를 모델로 적용할 수 있도록 특징을 뽑아 어떤 값으로 바꿔서 수치화한다.\n",
    "이번 절에서는 사이킷런을 사용해 텍스트 데이터를 수치화하는 세 가지 방법에 대해 알아보낟.\n",
    "참고로 세 가지 방법 모두 텍스트 데이터를 다루면서 자주 사용하는 기법이므로 알아둔다면 도움이 될 것이다.\n",
    "관련 모듈의 목록은 다음과 같다.\n",
    "\n",
    "- CountVectorizer\n",
    "- TfidfVectorizer\n",
    "- HashingVectorizer\n",
    "\n",
    "세 가지 방법 모두 텍스트를 벡터로 만드는 방법이다.\n",
    "`CountVectorizer`는 단순히 각 텍스트에서 횟수를 기준으로 특징을 추출하는 방법이다.\n",
    "`TfidfVectorizer`는 TF-IDF라는 값을 사용해 텍스트에서 특징을 추출한다.\n",
    "마지막으로 `HashingVectorizer`는 앞에서 설명한 `CountVectorizer`와 동일한 방법이지만\n",
    "텍스트를 처리할 때 해시 함수를 사용하기 때문에 실행 시간을 크게 줄일 수 있다.\n",
    "따라서 텍스트의 크기가 클수록 `HashingVectorizer`를 사용하는 것이 효율적이다.\n",
    "\n",
    "여기서는 세 가지 특징 추출 기법 중에서 `CountVectorizer`와 `TfidfVectorizer`에 대해서 알아보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16546b38",
   "metadata": {},
   "source": [
    "### CountVectorizer\n",
    "\n",
    "`CountVectorizer`는 이름에서도 확인할 수 있듯이 텍스트 데이터에서 횟수를 기준으로 특징을 추출하는 방법이다.\n",
    "여기서 어떤 단위의 횟수를 셀 것인지는 선택 사항이다.\n",
    "여기서 말하는 단위는 단어가 될 수도 있고, 문자 하나하나가 될 수도 있다.\n",
    "보통은 텍스트에서 단어를 기준으로 횟수를 측정하는데, 문장을 입력으로 받아 단어의 횟수를 측정한 뒤 벡터로 만든다.\n",
    "\n",
    "`CountVectorizer`를 사용하려면 먼저 객체를 만들어야 한다. 그리고 이 객체에 특정 텍스트를 적합시켜야 한다.\n",
    "여기서 말하는 적합의 의미는 횟수를 셀 단어의 목록을 만드는 과정이다.\n",
    "그다음에 횟수를 기준으로 해당 텍스트를 벡터화한다.\n",
    "\n",
    "예를 들어, \"나는 매일 공부를 한다\"라는 문장을 횟수값으로 이뤄진 벡터로 만든다면, 우선 단어 사전을 정의해야 한다.\n",
    "이때 단어 사전이 \"나는\", \"너가\", \"매일\", \"공부를\", \"한다\", \"좋아한다\"라는 6개의 단어로 구성돼 있다고 한다면\n",
    "\"나는 매일 공부를 한다\" 문장의 경우 \\[1, 0, 1, 1, 1, 0\\]이라는 벡터로 바뀔 것이다.\n",
    "즉, 첫 번째 단어인 \"나는\"이라는 단어가 1번 나오므로 1이라는 값을 가지고,\n",
    "두 번째 단어인 \"너가\"라는 단어는 나오지 않으므로 0이 된다.\n",
    "이러한 방식으로 나머지 단어 사전의 단어에 대해서도 횟수를 세서 해당 횟수를 벡터 값으로 만든다.\n",
    "만약 \"나는 매일 매일 공부를 한다.\"라는 문장에 대해서는 단어 사전의 세 번째 단어인 \"매일\"이 두 번 나오므로\n",
    "\\[1, 0, 2, 1, 1, 0\\]이라는 벡터로 바뀔 것이다.\n",
    "\n",
    "이제 사이킷런의 모듈을 사용해 직접 구현해 보자.\n",
    "우선 특징 추출 모듈 `sklearn.feature_extration.text`에서 `CountVectorizer`를 불러오자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4d2bb96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29b04eb",
   "metadata": {},
   "source": [
    "이번에는 텍스트 데이터를 불러오자. 여기서는 특정 데이터를 사용하지 않고 리스트로 텍스트 데이터를 직접 정의해서 사용한다.\n",
    "그리고 `CountVectorizer` 객체를 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "754cddcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = [\"나는 배가 고프다\", \"내일 점심 뭐먹지\", \"내일 공부 해야겠다\", \"점심 먹고 공부 해야지\"]\n",
    "\n",
    "count_vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ff49ed",
   "metadata": {},
   "source": [
    "우선은 앞에서 설명한 것처럼 단어 사전을 만들어야 한다.\n",
    "생성한 객체에 `fit` 함수를 사용해 데이터를 적용하면 자동으로 단어 사전을 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9c96ccf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'나는': 2, '배가': 6, '고프다': 0, '내일': 3, '점심': 7, '뭐먹지': 5, '공부': 1, '해야겠다': 8, '먹고': 4, '해야지': 9}\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer.fit(text_data)\n",
    "print(count_vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb4ddf2",
   "metadata": {},
   "source": [
    "데이터를 적용한 후 단어 사전을 출력해보면 각 단어에 대해 숫자들이 사전 형태로 구성돼 있다.\n",
    "이제 텍스트 데이터를 실제로 벡터로 만들어보자.\n",
    "정의한 텍스트 데이터 중에서 하나만 선택해서 벡터로 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ee7e41fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 1 0 0 0 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "sentence = [text_data[0]] # [\"나는 배가 고프다\"]\n",
    "print(count_vectorizer.transform(sentence).toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3471606b",
   "metadata": {},
   "source": [
    "\"나는 배가 고프다\"라는 문장을 벡터로 만들었다.\n",
    "각 단어가 1번씩 나왔으므로 해당 단어 사전 순서에 맞게 1 값을 가진다.\n",
    "이처럼 매우 간단하게 텍스트 데이터에서 특징을 추출할 수 있다.\n",
    "횟수를 사용해서 벡터를 만들기 때문에 직관적이고 간단해서 여러 상황에서 사용할 수 있다는 장점이 있다.\n",
    "하지만 단순히 횟수만을 특징으로 잡기 때문에 큰 의미가 없지만 자주 사용되는 단어들,\n",
    "예를 들면 조사 혹은 지시대명사가 높은 특징 값을 가지기 때문에 유의미하게 사용하기 어려울 수 있다.\n",
    "이제 이러한 문제점을 해결할 수 있는 TF-IDF 방식의 특징 추출 방법을 살펴보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d168a011",
   "metadata": {},
   "source": [
    "### TfidfVectorizer\n",
    "\n",
    "`TfidfVectorizer`는 TF-IDF라는 특정한 값을 사용해서 텍스트 데이터의 특징을 추출하는 방법이다.\n",
    "각 값이 의미하는 바를 간단히 설명하면 TF(Term Frequency)란 특정 단어가 하나의 데이터 안에서 등장하는 횟수를 의미한다.\n",
    "그리고 DF(Document Frequency)는 문서 빈도 값으로, 특정 단어가 여러 데이터에 자주 등장하는지를 알려주는 지표다.\n",
    "IDF(Inverse Document Frequency)는 이 값에 역수를 취해서 구할 수 있으며, 특정 단어가 다른 데이터에 등장하지 않을수록 값이 커진다는 것을 의미한다.\n",
    "TF-IDF란 이 두 값을 곱해서 사용하므로 어떤 단어가 해당 문서에 자주 등장하지만 다른 문서에는 많이 없는 단어일수록 높은 값을 가지게 된다.\n",
    "따라서 조사나 지시대명사처럼 자주 등장하는 단어는 TF 값은 크지만 IDF 값은 작어지므로 `TfidfVectorizer`는\n",
    "`CountVectorizer`가 가진 문제점을 해결할 수 있다.\n",
    "\n",
    "이제 사이킷런의 `TfidfVectorizer`를 사용하는 방법을 알아보자.\n",
    "기본적인 방법은 `CountVectorizer`와 거의 유사하다.\n",
    "결괏값만 단어의 출현 횟수가 아닌 각 단어의 TF-IDF 값으로 나오는 것만 다르다.\n",
    "우선은 `TfidfVectorizer`를 불러오자. 마찬가지로 사이킷런의 특징 추출 모듈에서 불러오면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8e0051a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c635e7c5",
   "metadata": {},
   "source": [
    "이제 특징을 추출한 데이터를 정의하고 해당 객체를 생성한다.\n",
    "앞에서 사용했던 데이터와 동일한 데이터로 진행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "de8a7fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = [\"나는 배가 고프다\", \"내일 점심 뭐먹지\", \"내일 공부 해야겠다\", \"점심 먹고 공부 해야지\"]\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d75faa",
   "metadata": {},
   "source": [
    "`TfidfVectorizer`를 사용할 때도 앞에서 했던 것과 동일하게 먼저 단어 사전을 만들어야 한다.\n",
    "단어 사전을 만든 후 단어 사전의 목록을 출력하고, 해당 데이터의 한 문장만 객체에 적용해 벡터로 바뀐 값도 출력해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e33c6a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'나는': 2, '배가': 6, '고프다': 0, '내일': 3, '점심': 7, '뭐먹지': 5, '공부': 1, '해야겠다': 8, '먹고': 4, '해야지': 9}\n",
      "[[0.57735027 0.         0.57735027 0.         0.         0.\n",
      "  0.57735027 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.52640543 0.         0.66767854\n",
      "  0.         0.52640543 0.         0.        ]\n",
      " [0.         0.52640543 0.         0.52640543 0.         0.\n",
      "  0.         0.         0.66767854 0.        ]\n",
      " [0.         0.43779123 0.         0.         0.55528266 0.\n",
      "  0.         0.43779123 0.         0.55528266]]\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer.fit(text_data)\n",
    "print(tfidf_vectorizer.vocabulary_)\n",
    "\n",
    "sentence = [text_data[3]] # ['점심 먹고 공부 해야지']\n",
    "print(tfidf_vectorizer.transform(text_data).toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e961f00",
   "metadata": {},
   "source": [
    "단어 사전의 앞에서 만든 것과 동일한데, 특정 문장을 벡터로 만든 값이 `CountVectorizer`의 결과와 다르다.\n",
    "예시로 사용한 문장은 \"점심 먹고 공부 해야지\"라는 문장인데 여기서 1, 4, 7, 9번째 단어를 제외한 단어들은 해당 문장에 사용되지 않아서 모두 0 값이 나왔다.\n",
    "그리고 문장에 나온 단어에 대한 TF-IDF 값을 살펴보자.\n",
    "우선 1, 7번째 단어인 '공부'와 '점심'이라는 단어는 0.4 정도의 값을 가지고 4, 9번째 단어인 '먹고'와 '해야지'는 0.5 정도의 값으로 앞의 두 단어보다 높은 값을 가진다.\n",
    "TF-IDF 측정 방법을 생각해보면 우선 해당 문장 안에서 단어의 출현 빈도를 측정하고 해당 단어가 다른 데이터에서는 잘 나오지 않는 값일수록 높은 값을 가진다고 했다.\n",
    "이 문장에서 4단어 모두 한 번씩 나왔으나 '먹고'와 '해야지'의 경우 다른 데이터에는 나오지 않은 단어이기 때문에 앞선 두 단어보다 높은 값이 나왔다.\n",
    "\n",
    "이처럼 특징 추출 방법으로 TF-IDF 값을 사용할 경우 단순 횟수를 이용하는 것보다 각 단어의 특성을 좀 더 잘 반영할 수 있다.\n",
    "따라서 모델에 적용할 때도 단순히 횟수를 이용해 특징을 추출한 `CountVectorizer`보다 TF-IDF 값으로 특징을 추출한 `TfidfVectorizer`를 사용하는 편이 일반적으로 좀 더 좋은 결과를 만들어낸다.\n",
    "\n",
    "지금까지 사이킷런을 사용해서 모델을 만드는 방법, 데이터 분리, 특징 추출 방법에 대해 알아봤다.\n",
    "사이킷런에는 여기서 소개한 기능뿐 아니라 다양한 모듈을 제공하고 있으므로 머신러닝 모델을 통해 문제를 해결하려 한다면 사이킷런 라이브러리를 사용하는 것이 매우 효율적일 것이다.\n",
    "그뿐만 아니라 텐서플로 등 다른 라이브러리를 사용해서 딥러닝 모델을 만든다하더라도 데이터 분리나 특징 추출 등 사이킷런의 전처리 모듈은 유용하게 활용될 수 있다.\n",
    "다음 장부터 실습할 때도 실제로 사이킷런을 사용하는 내용이 나오므로 사용법을 확실히 익혀두기를 권장한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfc63c2",
   "metadata": {},
   "source": [
    "## 자연어 토크나이징 도구\n",
    "\n",
    "자연어 처리를 위해서는 우선 텍스트에 대한 정보를 단위별로 나누는 것이 일반적이다.\n",
    "예를 들어, 영화 리뷰 내용을 예측한다고 하면 한 문장을 단어 단위로 쪼개서 분석할 수 있다.\n",
    "이처럼 예측해야 할 입력 정보(문장 또는 발화)를 하나의 특정 기본 단위로 자르는 것을 토크나이징이라고 한다.\n",
    "파이썬을 이용하면 이러한 작업을 라이브러리를 통해 간편하게 처리할 수 있다.\n",
    "\n",
    "이번 절에서는 토크나이징 도구에 대해 간단히 설명하고, 설치 방법과 단어, 형태소 토크나이징과 문장 토크나이징 방법을 이야기하고자 한다.\n",
    "그리고 토크나이징을 할 때 언어의 특징에 따라 처리 방법이 달라지므로 이 책에서는 영어 토크나이징과 한글 토크나이징을 구분해서 따로 설명하겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769149e6",
   "metadata": {},
   "source": [
    "### 영어로 토크나이징 라이브러리\n",
    "\n",
    "이번 절에서는 영어 토크나이징 작업을 수행할 수 있는 라이브러리를 소개한다.\n",
    "영어의 경우 NLTK(Natural Language Toolkit)와 Spacy가 토크나이징에 많이 쓰이는 대표적인 라이브러리다.\n",
    "이 두 라이브러리는 영어 텍스트에 대해 전처리 및 분석을 하기 위한 도구로 유명하다.\n",
    "\n",
    "#### NLTK\n",
    "\n",
    "NLTK는 파이썬에서 영어 텍스트 전처리 작업을 하는 데 많이 쓰이는 라이브러리다.\n",
    "이 라이브러리는 50여 개가 넘는 말뭉치 리소스를 활용해 영어 텍스트를 분석할 수 있게 제공한다.\n",
    "직관적으로 함수를 쉽게 사용할 수 있게 구성돼 있어 빠르게 텍스트 전처리를 할 수 있다.\n",
    "\n",
    "#### 토크나이징\n",
    "\n",
    "토크나이징이란 텍스트에 대해 특정 기준 단위로 문장을 나누는 것을 의미한다.\n",
    "예를 들면, 문장을 단어 기준으로 나누거나 전체 글을 문장 단위로 나누는 것들이 토크나이징에 해당한다.\n",
    "파이썬에서 간단하게 문자열에 대해 `split` 함수를 사용해서 나눌 수도 있지만 라이브러리를 사용하면 훨씬 더 간편하고 효과적으로 토크나이징할 수 있다.\n",
    "\n",
    "#### 단어 단위 토크나이징\n",
    "\n",
    "텍스트 데이터를 각 단어를 기준으로 토크나이징해보자.\n",
    "우선 라이브러리 `tokenize` 모듈에서 `word_tokenize`를 불러온 후 사용하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bb0852b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "# nltk.download('all-corpora')\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4f492090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural', 'language', 'processing', '(', 'NLP', ')', 'is', 'a', 'subfield', 'of', 'computer', 'science', ',', 'information', 'engineering', ',', 'and', 'artificial', 'intelligence', 'concerned', 'with', 'the', 'interactions', 'between', 'computers', 'and', 'human', '(', 'natural', ')', 'languages', ',', 'in', 'particular', 'how', 'to', 'program', 'computers', 'to', 'process', 'and', 'analyze', 'large', 'amounts', 'of', 'natural', 'language', 'data', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "sentence = \"Natural language processing (NLP) is a subfield of computer science, information engineering, and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of natural language data.\"\n",
    "\n",
    "print(word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5d881a",
   "metadata": {},
   "source": [
    "영어 텍스트를 정의한 후 `word_tokenize` 함수에 적용하면 위와 같이 구분된 리스트를 받을 수 있다.\n",
    "결과를 보면 모두 단어로 구분돼 있고, 특수 문자의 경우 따로 간단하게 토크나이징된 결과를 받을 수 있다.\n",
    "이제 단어 단위로 자르는 것이 아니라 문장 단위로 잘라보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca20fae2",
   "metadata": {},
   "source": [
    "#### 문장 단위 토크나이징\n",
    "\n",
    "경우에 따라 텍스트 데이터를 우선 단어가 아닌 문장으로 나눠야 하는 경우가 있다.\n",
    "예를 들어, 데이터가 문단으로 구성돼 있어서 문단을 먼저 문장으로 나눈 후 그 결과를 다시 단어로 나눠야 하는 경우가 있다.\n",
    "이런 경우에 문장 단위의 토크나이징이 필요하다.\n",
    "역시 NLTK의 라이브러리를 사용하면 쉽게 토크나이징 할 수 있다.\n",
    "앞서 불러왔던 것처럼 문장 토크나이징할 수 있다.\n",
    "\n",
    "그뿐만 아니라 NLTK 라이브러리의 경우 토크나이징 외에도 자연어 처리에 유용한 기능들을 제공한다.\n",
    "대표적으로 텍스트 데이터를 전처리할 때 경우에 따라 불용어를 제거해야 할 때가 있다.\n",
    "여기서 불용어란 큰 의미를 가지지 않는 단어를 의미한다.\n",
    "예를 들어, 영어에서는 'a', 'the' 같은 관사나 'is' 같이 자주 출현하는 단어들을 불용어라 한다.\n",
    "NLTK 라이브러리에는 불용어 사전이 내장돼 있어서 따로 불용어를 정의할 필요 없이 바로 사용할 수 있다.\n",
    "이처럼 NLTK를 사용하면 자연어 처리 전반에 유용한 기능들을 활용해 효율적으로 문제를 해결할 수 있다.\n",
    "\n",
    "이제 또 다른 토크나이징 도구인 Spacy에 대해 알아보자.\n",
    "Spacy도 NLTK와 마찬가지로 매우 간단하게 텍스트를 토크나이징할 수 있는 라이브러리이고 사용법 또한 매우 간단하기 때문에 쉽게 익힐 수 있을 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbd5244",
   "metadata": {},
   "source": [
    "#### Spacy\n",
    "\n",
    "Spacy는 NLTK와 같은 오픈소스 라이브러리다.\n",
    "주로 교육, 연구 목적이 아닌 상업용 목적으로 만들어졌다는 점에서 NLTK와 다른 목적으로 만들어진 라이브러리다.\n",
    "Spacy는 현재 영어를 포함한 8개 국어에 대한 자연어 전처리 모듈을 제공하고, 빠른 속도로 전처리할 수 있다고 한다.\n",
    "또한 쉽게 설치하고 원하는 언어에 대한 전처리를 한 번에 해결할 수 있다는 장점이 있으며, 특히 딥러닝 언어 모델의 개발도 지원하고 있어 매력적이다.\n",
    "\n",
    "#### Spacy 토크나이징\n",
    "\n",
    "NLTK 라이브러리에서는 단어 단위의 토크나이징 함수는 `word_tokenize()`, 문장 단위로 토크나이징 함수는 `sent_tokenize()`로 서로 구분돼 있었다.\n",
    "하지만 Spacy에서는 두 경우 모두 동일한 모듈을 통해 토크나이징한다.\n",
    "우선 객체를 생성하기 위해 라이브러리를 불러오자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3369da38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6a82616c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en\")\n",
    "sentence = \"Natural language processing (NLP) is a subfield of computer science, information engineering, and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of natural language data.\"\n",
    "\n",
    "doc = nlp(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176e5616",
   "metadata": {},
   "source": [
    "먼저 `spacy.load('en')`을 통해 토크나이징할 객체를 생성해서 `nlp` 변수에 할당하다.\n",
    "그리고 토크나이징할 텍스트를 `sentence`에 할당해서 `nlp(sentence)`를 실행해 `nlp` 객체에 대해 호출하자.\n",
    "그러고 나면 텍스트에 대해 구문 분석 객체를 반환하는데 이를 `doc` 변수에 할당한다.\n",
    "이제 `doc` 객체를 가지고 입력한 텍스트에 대한 단어 토크나이징과 문장 토크나이징을 할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c531ffb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural', 'language', 'processing', '(', 'NLP', ')', 'is', 'a', 'subfield', 'of', 'computer', 'science', ',', 'information', 'engineering', ',', 'and', 'artificial', 'intelligence', 'concerned', 'with', 'the', 'interactions', 'between', 'computers', 'and', 'human', '(', 'natural', ')', 'languages', ',', 'in', 'particular', 'how', 'to', 'program', 'computers', 'to', 'process', 'and', 'analyze', 'large', 'amounts', 'of', 'natural', 'language', 'data', '.']\n",
      "['Natural language processing (NLP) is a subfield of computer science, information engineering, and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of natural language data.']\n"
     ]
    }
   ],
   "source": [
    "word_tokenized_sentence = [token.text for token in doc]\n",
    "sentence_tokenized_list = [sent.text for sent in doc.sents]\n",
    "print(word_tokenized_sentence)\n",
    "print(sentence_tokenized_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ecfd86",
   "metadata": {},
   "source": [
    "토크나이징할 때는 `doc` 객체를 활용해 `[token.text for token in doc]`과 같이 리스트 컴프리헨션을 활용하면 간단하게 토크나이징 결과를 확인할 수 있다.\n",
    "리스트 컴프리헨션은 파이썬에서 제공하는 기능으로 한 리스트의 모든 원소 각각에 어떤 함수를 적용한 후,\n",
    "그 반환값을 원소로 가지는 다른 리스트를 쉽게 만들 수 있다.\n",
    "`doc` 객체에 대해 반복문을 사용하면 단어를 기준으로 토큰이 나오고 `doc.sents` 값에 대해 반복문을 사용하면 문장을 기준으로 토크나이징된다.\n",
    "이 값을 리스트 컴프리헨션을 통해 각각 리스트로 만들었다.\n",
    "이처럼 단어 기준, 문장 기준 토크나이징은 매우 유사하지만 조금 다른 구조로 생성할 수 있다.\n",
    "\n",
    "NLTK는 함수를 통해 토크나이징을 처리했지만 Spacy는 객체를 생성하는 방식으로 구현돼 있다.\n",
    "이처럼 객체를 생성하는 이유는 이 객체를 통해 단순히 토크나이징뿐 아니라 갖가지 다른 자연어 전처리 기능을 제공할 수 있기 때문이다.\n",
    "\n",
    "사용법을 보면 NLTK와 Spacy는 간단하게 사용할 수 있다는 것을 알 수 있다.\n",
    "하지만 사용법에 저마다 특색이 있거, 토크나이징 외에 제공되는 기능이 서로 다르므로 두 라이브러리 모두 알아두고 적재적소에 알맞게 사용하면 된다.\n",
    "\n",
    "지금가지 두 라이브러리를 통해 영어 텍스트를 토크나이징하는 방법을 알아봤다.\n",
    "하지만 이러한 영어 토크나이징 도구는 한국어에 적용할 수 없다는 것이 큰 문제점이다.\n",
    "이어지는 절에서는 한글 텍스트 데이터를 어떻게 토크나이징하는지 알아보겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7720a6",
   "metadata": {},
   "source": [
    "### 한글 토크나이징 라이브러리\n",
    "\n",
    "자연어 처리에서 각 언어마다 모두 특징이 다르기 때문에 천편일률적으로 동일한 방법을 적용하기는 어렵다.\n",
    "한글에도 NLTK나 Spacy 같은 도구를 사용할 수 있으면 좋겠지만 언어 특성상 영어를 위한 도구를 사용하기에는 적합하지 않다.\n",
    "예를 들어, 영어에 없는 형태소 분석이나 음속 분리와 같은 내용은 앞서 소개한 라이브러리로는 다루기 어렵다.\n",
    "하지만 다행히도 영어 자연어 처리를 위한 도구와 같이 한글 자연어 처리를 돕는 도구가 있다.\n",
    "여러 가지 도구가 있지만 여기서는 한글 자연어 처리에 많이 사용하는 파이썬 라이브러리인 KoNLPy에 대해 알아보겠다.\n",
    "KoNLPy는 형태소 분석으로 형태소 단위의 토크나이징을 가능하게 할뿐만 아니라 구문 분석을 가능하게 해서 언어 분석을 하는 데 유용한 도구다.\n",
    "\n",
    "#### KoNLPy\n",
    "\n",
    "일단 각자 환경에 맞게 잘 설치하도록하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ba7da05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import konlpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f37283",
   "metadata": {},
   "source": [
    "#### 형태소 단위 토크나이징\n",
    "\n",
    "한글 텍스트의 경우에는 형태소 단위 토크나이징이 필요할 때가 있다.\n",
    "KoNLPy에서는 여러 형태소 분리기를 제공하며, 각 형태소 분석기별로 분석한 결과는 다를 수 있다.\n",
    "각 형태소 분석기는 클래스 형태로 돼 있고, 이를 객체로 생성한 후 메소드를 호출해서 토크나이징 할 수 있다.\n",
    "\n",
    "#### 형태소 분석 및 품사 태깅\n",
    "\n",
    "형태소 분석을 설명하기 전에 먼저 형태소가 무엇인지 알아보자.\n",
    "형태소란 의미를 가지는 가장 작은 단위로서 더 쪼개지면 의미를 상실하는 것들을 말한다.\n",
    "따라서 형태소 분석이란 의미를 가지는 단위를 기준으로 문장을 살펴보는 것을 의미한다.\n",
    "\n",
    "- Hannanum\n",
    "- Kkma\n",
    "- Komoran\n",
    "- Mecab\n",
    "- Okt(Twitter)\n",
    "\n",
    "위 객체들은 모두 동일하게 형태소 분석 기능을 제공하는데, 각기 성능이 조금씩 다르므로 직접 비교해보고 자신의 데이터를 가장 잘 분석하는 분석기를 사용하길 권장한다.\n",
    "\n",
    "각 분석기의 사용법은 거의 비슷하므로 이 책에서는 그중 하나인 Okt를 예로 들어 설명한다.\n",
    "Okt는 원래 이름이 Twitter였으나 0.5.0 버전 이후로 Okt로 이름이 바뀌었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8f6e844c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539f5770",
   "metadata": {},
   "source": [
    "Okt 객체는 총 4개 함수를 제공한다.\n",
    "- okt.morphs()\n",
    "    텍스트를 형태소 단위로 나눈다. 옵션으로는 norm과 stem이 있다. 각각 True 혹은 Flase 값을 받으며, norm은 normalize의 약자로서 문장을 정규화하는 역할을 하고, stem은 각 단어에서 어간을 추출하는 기능이다.\n",
    "    각각 True로 설정하면 각 기능이 적용된다. 옵션을 지정하지 않으면 기본값은 둘 다 False로 설정된다.\n",
    "- okt.nouns()\n",
    "    텍스트에서 명사만 뽑아낸다.\n",
    "- okt.phrases()\n",
    "    텍스트에서 어절을 뽑아낸다.\n",
    "- okt.pos()\n",
    "    위의 세 함수는 어간/명사/어절 등을 추출해내는 추출기로 동작했다면 pos 함수는 각 품사를 태깅하는 역할을 한다.\n",
    "    품사를 태깅한다는 것은 주어진 텍스트를 형태소 단위로 나누고, 나눠진 각 형태소를 그에 해당하는 품사와 함께 리스트화하는 것을 의미한다.\n",
    "    이 함수에서도 옵션을 설정할 수 있는데, morphs 함수와 마찬가지로 norm, stem 옵션이 있고 추가적으로 join 함수가 있는데\n",
    "    이 옵션 값을 True로 설정하면 나눠진 형태소와 품사를 '형태소/품사' 형태로 같이 붙여서 리스트화한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d02e9a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['한글', '자연어', '처리', '는', '재밌다', '이제', '부터', '열심히', '해야지', 'ㅎㅎㅎ']\n",
      "['한글', '자연어', '처리', '는', '재밌다', '이제', '부터', '열심히', '하다', 'ㅎㅎㅎ']\n"
     ]
    }
   ],
   "source": [
    "text = \"한글 자연어 처리는 재밌다 이제부터 열심히 해야지ㅎㅎㅎ\"\n",
    "print(okt.morphs(text))\n",
    "print(okt.morphs(text, stem=True)) # 형태소 단위로 나눈 후 어간을 추출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94912611",
   "metadata": {},
   "source": [
    "어간 추출을 한 경우 \"해야지\"의 어간인 \"하다\"로 추출된 것을 볼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7909cecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['한글', '자연어', '처리', '이제']\n",
      "['한글', '한글 자연어', '한글 자연어 처리', '이제', '자연어', '처리']\n"
     ]
    }
   ],
   "source": [
    "print(okt.nouns(text))\n",
    "print(okt.phrases(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0eed363",
   "metadata": {},
   "source": [
    "nouns 함수를 사용한 경우에는 명사만 추출됐고 phrases 함수의 경우에는 어절 단위로 나뉘어서 추출됐다.\n",
    "\n",
    "이제 품사 태깅을 하는 함수인 pos 함수를 사용해 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1cbd1547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('한글', 'Noun'), ('자연어', 'Noun'), ('처리', 'Noun'), ('는', 'Josa'), ('재밌다', 'Adjective'), ('이제', 'Noun'), ('부터', 'Josa'), ('열심히', 'Adverb'), ('해야지', 'Verb'), ('ㅎㅎㅎ', 'KoreanParticle')]\n",
      "['한글/Noun', '자연어/Noun', '처리/Noun', '는/Josa', '재밌다/Adjective', '이제/Noun', '부터/Josa', '열심히/Adverb', '해야지/Verb', 'ㅎㅎㅎ/KoreanParticle']\n"
     ]
    }
   ],
   "source": [
    "print(okt.pos(text))\n",
    "print(okt.pos(text, join=True)) # 형태소와 품사를 붙여서 리스트화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8ab46e",
   "metadata": {},
   "source": [
    "join 옵션을 True로 설정한 경우 형태소와 품사가 함께 나오는 것을 볼 수 있다.\n",
    "경우에 따라 옵션을 설정하면서 사용하자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52dd97f",
   "metadata": {},
   "source": [
    "#### KoNLPy 데이터\n",
    "\n",
    "KoNLPy 라이브러리는 한글 자연어 처리에 활용할 수 있는 한글 데이터를 포함하고 있다.\n",
    "따라서 라이브러리를 통해 데이터를 바로 사용할 수 있으며, 데이터의 종류는 다음과 같다.\n",
    "\n",
    "- kolaw\n",
    "    한국 법률 말뭉치. 'constitution.txt' 파일로 저장돼 있다.\n",
    "- kobill\n",
    "    대한민국 국회 의안 말뭉치. 각 id 값을 가지는 의안으로 구성돼 있고 파일은 '1809890.txt'부터 '1809899.txt'까지로 구성돼 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b3266e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.corpus import kolaw\n",
    "from konlpy.corpus import kobill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "959eaffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'대한민국헌법\\n\\n유구한 역사와 전통에 '"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kolaw.open('constitution.txt').read()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "86c8d854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'지방공무원법 일부개정법률안\\n\\n(정의화의원 대표발의 )\\n\\n 의 안\\n 번 호\\n\\n9890\\n\\n발의연월일 : 2010.  11.  12.  \\n\\n발  의  자 : 정의화․이명수․김을동 \\n\\n이사철․여상규․안규백\\n\\n황영철․박영아․김정훈\\n\\n김학송 의원(10인)\\n\\n제안이유 및 주요내용\\n\\n  초등학교 저학년의 경우에도 부모의 따뜻한 사랑과 보살핌이 필요\\n\\n한 나이이나, 현재 공무원이 자녀를 양육하기 위하여 육아휴직을 할 \\n\\n수 있는 자녀의 나이는 만 6세 이하로 되어 있어 초등학교 저학년인 \\n\\n자녀를 돌보기 위해서는 해당 부모님은 일자리를 그만 두어야 하고 \\n\\n이는 곧 출산의욕을 저하시키는 문제로 이어질 수 있을 것임.\\n\\n  따라서 육아휴직이 가능한 자녀의 연령을 만 8세 이하로 개정하려\\n\\n는 것임(안 제63조제2항제4호).\\n\\n- 1 -\\n\\n\\x0c법률  제        호\\n\\n지방공무원법 일부개정법률안\\n\\n지방공무원법 일부를 다음과 같이 개정한다.\\n\\n제63조제2항제4호 중 “만 6세 이하의 초등학교 취학 전 자녀를”을 “만 \\n\\n8세 이하(취학 중인 경우에는 초등학교 2학년 이하를 말한다)의 자녀를”\\n\\n로 한다.\\n\\n부      칙\\n\\n이 법은 공포한 날부터 시행한다.\\n\\n- 3 -\\n\\n\\x0c신 ·구조문대비표\\n\\n현      행\\n\\n개   정   안\\n\\n제63조(휴직) ① (생  략)\\n\\n제63조(휴직) ① (현행과 같음)\\n\\n  ② 공무원이 다음 각 호의 어\\n\\n  ② -------------------------\\n\\n느 하나에 해당하는 사유로 휴\\n\\n----------------------------\\n\\n직을 원하면 임용권자는 휴직\\n\\n----------------------------\\n\\n을 명할 수 있다. 다만, 제4호\\n\\n-------------.---------------\\n\\n의 경우에는 대통령령으로 정\\n\\n----------------------------\\n\\n하는 특별한 사정이 없으면 휴\\n\\n----------------------------\\n\\n직을 명하여야 한다.\\n\\n--------------.\\n\\n  1. ∼ 3. (생  략)\\n\\n  1. ∼ 3. (현행과 같음)\\n\\n  4. 만 6세 이하의 초등학교 취\\n\\n  4. 만 8세 이하(취학 중인 경우\\n\\n학 전 자녀를 양육하기 위하\\n\\n에는 초등학교 2학년 이하를 \\n\\n여 필요하거나 여자공무원이 \\n\\n말한다)의 자녀를 ----------\\n\\n임신 또는 출산하게 되었을 \\n\\n---------------------------\\n\\n때\\n\\n---------------------------\\n\\n  5.⋅6. (생  략)\\n\\n  ③⋅④ (생  략)\\n\\n--------\\n\\n  5.⋅6. (현행과 같음)\\n\\n  ③⋅④ (현행과 같음)\\n\\n- 5 -\\n\\n\\x0c지방공무원법 일부개정법률안 등 비용추계서 미첨부사유서\\n1.  재정수반요인\\n\\n개정안에서 ｢국가공무원법｣  제71조제2항제4호 중 국가공무원의 육아\\n\\n휴직 가능 자녀의 연령을 만6세 이하에서 만8세 이하로 하고, ｢지방공\\n\\n무원법｣ 제63조제2항제4호 중 지방공무원의 육아휴직 가능 자녀의 연\\n\\n령을 만6세 이하에서 만8세 이하로 하고, ｢교육공무원법｣ 제44조제1항\\n\\n제7조 중 교육공무원의 육아휴직 가능 자녀의 연령을 만6세 이하에서 \\n\\n만8세 이하로 하고, ｢남녀고용평등과 일․가정 양립지원에 관한 법률｣ \\n\\n제19조제1항 중 근로자 육아휴직 가능 자녀연령을 만6세 이하에서 만\\n\\n8세 이하로 조정함에 따라 추가 재정소요가 예상됨.\\n\\n2.  미첨부  근거  규정\\n｢의안의 비용추계에 관한 규칙｣ 제3조제1항 단서 중 제1호(예상되는 비용이 연평균  10억원 미만\\n이거나  한시적인  경비로서  총  30억원  미만인  경우)에  해당함.\\n\\n3.  미첨부  사유\\n\\n개정안에서 국가․지방․교육공무원 및 근로자가 육아휴직을 신청할 \\n\\n수 있는 자녀의 연령을 만6세 이하에서 만8세 이하로 상향조정함에 \\n\\n따라 추가 재정소요가 예상된다. 동 법률 개정안이 2011년에 시행된다\\n\\n고 가정한 경우, 2010년 현재 자녀의 연령이 7세이고 육아휴직을 신청\\n\\n- 7 -\\n\\n\\x0c- 8 -\\n\\n하지 않은 국가․지방․교육공무원 및 근로자가 대상이 된다.\\n\\n대상연령의 확대됨에 따라 육아휴직신청자의 수가 어느 정도 늘어날 \\n\\n것으로 예상된다. 이 경우 발생하는 비용은 현행법에 따르면 월50만원\\n\\n이나 현재 관련법령 개정이 추진되고 있으며, 이에 따라 2011년에는 \\n\\n육아휴직자가 지급받는 월급여액에 비례하여 육아휴직급여가 지급되\\n\\n기 때문에 법령개정을 가정하고 추계한다. 이러한 경우 육아휴직급여\\n\\n액은 육아휴직자가 지급받는 월급여의 40%에 해당한다. 육아휴직자가 \\n\\n발생한 경우 발생하는 비용은 대체인력 고용인건비와 육아휴직자가 \\n\\n받는 월급여액의 40%이다. 이와 대비하여 육아휴직자에게 지급하던 \\n\\n임금은 더 이상 발생하지 않는다. 따라서 실제 발생하는 순비용은 육\\n\\n아휴직자에게 지급하던 월 급여액과 연령 확대에 따라 발생하는 비용\\n\\n인 육아휴직자가 받던 월급여액의 40%와 대체인력 고용인건비의 차\\n\\n액인데 이 값이 0보다 크면 추가 재정소요는 발생하지 않는다고 볼 \\n\\n수 있다.\\n\\n추가비용 발생여부를 정확하게 알아보기 위하여 비용에 대한 수리모\\n\\n델을 만들고 이에 따라 비용발생 여부를 알아보기로 하자. 모델에 사\\n\\n용되는 변수를 다음과 같이 정의한다.\\n\\n발생비용 : N×p×X + N×육아휴직급여액 - N×P\\n\\nN\\n\\nP\\n\\n: 육아휴직대상자의 수\\n\\n: 육아휴직대상자의 월급여액\\n\\n\\x0cp\\n\\nX\\n\\n: 육아휴직자가 발생한 경우 대체 고용할 확률\\n\\n: 대체 고용한 인력에게 지급하는 월급여액\\n\\n위의 수식에서 육아휴직급여액은 육아휴직자 월급여액의 40%까지 지\\n\\n급할 예정이므로 육아휴직급여액은 P×40%이다. 육아휴직자가 발생한 \\n\\n경우 대체 고용할 확률 p는 고용노동부의 육아휴직 관련 자료를 이용\\n\\n한다. 고용노동부에 따르면 2011년의 경우 육아휴직급여 대상자는 \\n\\n40,923명이며, 육아휴직에 따른 대체인력 고용 예상인원은 2,836명이\\n\\n다. 2007년부터 2011년까지의 현황을 정리하면 다음의 [표]와 같다.\\n\\n[표]  육아휴직급여  수급자의  수  및  대체인력  고용  현황:  2007~2011년\\n\\n(단위:  명,  % )\\n\\n2007\\n\\n2008\\n\\n2009\\n\\n2010\\n\\n2011\\n\\n평균\\n\\n육아휴직급여  수급자(A)\\n\\n21,185\\n\\n29,145\\n\\n35,400\\n\\n41,291\\n\\n43,899\\n\\n34,184\\n\\n대체인력  채용(B)\\n\\n796\\n\\n1,658\\n\\n1,957\\n\\n2,396\\n\\n2,836\\n\\n1,929\\n\\n비  율(B/A)\\n\\n3.8\\n\\n5.7\\n\\n5.5\\n\\n5.8\\n\\n6.5\\n\\n5.6\\n\\n자료: 고용노동부  자료를  바탕으로  국회예산정책처  작성\\n\\n위의 [표]의 자료에 따라 육아휴직자가 발생한 경우 대체 고용할 확률 \\n\\np의 값은 5.6%라고 가정한다. 그리고 비용이 발생한다고 가정하여 위\\n\\n의 수식을 다시 작성하면 다음의 수식과 같다.\\n\\nN×p×X + N×육아휴직급여액 - N×P > 0\\n\\n(1)\\n\\n- 9 -\\n\\n\\x0c- 10 -\\n\\nN×5.6%×X + N×P×40% - N×P > 0\\n\\n0.056×X > 0.6P\\n\\nX > 10.7×P\\n\\n(2)\\n\\n(3)\\n\\n(5)\\n\\n위의 수식에 육아휴직자가 받는 월 급여액을 대입하여 대체고용인력\\n\\n자에게 지급하는 월 급여액을 추정하여 보자. 육아휴직자가 월 200만\\n\\n원을 받는다고 가정하면, 대체고용인력자에게 육아휴직자가 받는 월 \\n\\n급여액의 10.7배에 달하는 월 21,428,571원 이상을 지급해야 추가 비용\\n\\n이 발생한다. 대체고용인력자에게 육아휴직자보다 더 많은 월급여액을 \\n\\n주지는 않을 것이고 그리고 10여배 이상 월급을 주지도 않을 것이기 \\n\\n때문에 추가 비용이 발생한다고 보기 힘들다. 위의 수식에서 대체인력 \\n\\n고용확률 p를 20%로 가정하더라도(이 경우 X > 3×P) 200만원 받는 \\n\\n육아휴직자 대체인력에게 월 600만원 이상을 지급해야 추가 비용이 \\n\\n발생한다.\\n\\n행정안전부의 통계자료(행정안전부 통계연감)에서는 지방공무원의 육\\n\\n아휴직 현황자료를 보여주고 있다. 여기서 육아휴직자가 발생한 경우 \\n\\n대체인력을 주로 임용대기자 또는 일용직을 활용하는 것으로 보인다. \\n\\n따라서 공무원의 경우에도 [표]에서 보여주는 일반기업체의 대체인력 \\n\\n고용확률과 차이는 크지 않을 것으로 보인다.\\n\\n이상의 논의를 바탕으로 육아휴직기간을 만6에서 만8세로 연장하더라\\n\\n도 법률 개정에 따른 추가 비용은 발생하지 않을 것으로 예상된다.\\n\\n\\x0c4.  작성자\\n\\n국회예산정책처 법안비용추계1팀\\n\\n팀      장   정 문 종\\n\\n예산분석관   김 태 완\\n\\n(02-788-4649, tanzania@assembly.go.kr)\\n\\n- 11 -\\n\\n\\x0c'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kobill.open('1809890.txt').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f60b887",
   "metadata": {},
   "source": [
    "## 그 밖의 라이브러리(전처리)\n",
    "\n",
    "### Numpy\n",
    "\n",
    "#### 배열\n",
    "\n",
    "- ndarray.ndim\n",
    "    배열의 축(차원)의 수를 반환한다.\n",
    "- ndarray.shape\n",
    "    배열의 형태를 반환한다. 예를 들어, 2x3 크기의 2차원 배열이 있다면 이 배열의 shape은 (2,3)이 된다.\n",
    "- ndarray.size\n",
    "    배열 내 원소의 총 개수를 반환한다.\n",
    "- ndarray.dtype\n",
    "    배열 내 원소들의 자료형을 반환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a3191415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "(3, 3)\n",
      "9\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array([[1,2,3], [1,5,9], [3,5,7]])\n",
    "\n",
    "print(a.ndim)\n",
    "print(a.shape)\n",
    "print(a.size)\n",
    "print(a.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604dfd9c",
   "metadata": {},
   "source": [
    "- numpy.zeros\n",
    "    모든 배열의 원소가 0인 배열을 생성한다.\n",
    "- numpy.ones\n",
    "    모든 배열의 원소가 1인 배열을 생성한다.\n",
    "- numpy.empty\n",
    "    배열의 크기만 정해주고 원소는 초기화하지 않은 배열을 생성한다.\n",
    "    원소에는 매우 크거나 작은 값이 들어간다.\n",
    "- numpy.arange\n",
    "    파이썬의 range 함수와 유사한 형태로 배열을 생성할 수 있다.\n",
    "    배열의 원소들이 수열을 구성한다.\n",
    "- numpy.full\n",
    "    배열의 모든 값이 하나의 상수인 배열을 생성한다.\n",
    "- numpy.eye\n",
    "    지정한 크기의 단위행렬을 생성한다.\n",
    "- numpy.random.random\n",
    "    배열의 원소를 임의의 값으로 생성한다.\n",
    "    값은 0부터 1사이의 값으로 지정된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d77ff46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "[[1.]\n",
      " [1.]]\n",
      "[[4.94e-324 2.96e-323]\n",
      " [3.16e-322 9.88e-324]]\n",
      "[10 15 20 25]\n",
      "[[4 4]\n",
      " [4 4]]\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.zeros((2,3))\n",
    "print(a)\n",
    "\n",
    "b = np.ones((2,1))\n",
    "print(b)\n",
    "\n",
    "c = np.empty((2,2))\n",
    "print(c)\n",
    "\n",
    "d = np.arange(10, 30, 5)\n",
    "print(d)\n",
    "\n",
    "e = np.full((2, 2), 4)\n",
    "print(e)\n",
    "\n",
    "f = np.eye(3)\n",
    "print(f)\n",
    "g = np.random.random((2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d1b94a",
   "metadata": {},
   "source": [
    "#### 기본 연산\n",
    "\n",
    "넘파이는 배열끼리 연산할 때 빠르고 사용하기 쉬운 여러 연산 함수를 제공한다.\n",
    "넘파이에서 제공하는 기본 배열 연산에 알아보자.\n",
    "\n",
    "넘파이는 배열의 기본적인 사칙 연산을 모두 지원한다.\n",
    "주의할 점은 벡터끼리의 곱셈과 내적을 구분해야 한다는 점이다.\n",
    "연산의 경우에는 벡터끼리 사용할 경우 원소별 곱셈을 의미한다.\n",
    "벡터의 내적인 경우에는 `dot` 함수를 사용해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dff7c4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11 22 33]\n",
      "[11 22 33]\n",
      "[ 9 18 27]\n",
      "[ 9 18 27]\n",
      "[1 4 9]\n",
      "[ True False False]\n",
      "[[10 40]\n",
      " [90 40]]\n",
      "[[ 70  40]\n",
      " [150 100]]\n",
      "[[ 70  40]\n",
      " [150 100]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1, 2, 3])\n",
    "b = np.array([10, 20, 30])\n",
    "print(a+b)\n",
    "print(np.add(a,b))\n",
    "print(b-a)\n",
    "print(np.subtract(b,a))\n",
    "print(a**2)\n",
    "print(b<15)\n",
    "\n",
    "C = np.array([[1, 2],\n",
    "              [3, 4]])\n",
    "D = np.array([[10, 20],\n",
    "              [30, 10]])\n",
    "print(C*D)\n",
    "print(np.dot(C,D))\n",
    "print(C.dot(D))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddf3d36",
   "metadata": {},
   "source": [
    "위의 기본적인 연산 외에 중요한 연산 기능은 축을 기준으로 한 연산이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7785a657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7 11 15 19]\n",
      "[10 26 16]\n",
      "[4 8 7]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[ 1, 2, 3, 4],\n",
    "              [ 5, 6, 7, 8],\n",
    "              [ 1, 3, 5, 7]])\n",
    "\n",
    "print(a.sum(axis=0))\n",
    "\n",
    "print(a.sum(axis=1))\n",
    "\n",
    "print(a.max(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3193e77d",
   "metadata": {},
   "source": [
    "#### 넘파이 배열 인덱싱, 슬라이싱\n",
    "\n",
    "넘파이 배열은 파이썬 리스트와 마찬가지로 인덱싱, 슬라이싱 기능을 제공한다.\n",
    "인덱싱이란 배열에서 특정 원소를 뽑아내는 것이며, 슬라이싱이란 배열에서 특정 구간의 값을 뽑아내는 것이다.\n",
    "일차원 배열의 경우 인덱싱과 슬라이싱은 파이썬 리스트 인덱싱과 슬라이싱과 매우 비슷하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dd2d60e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "7\n",
      "[3 4 5]\n",
      "[3 4 5 6 7]\n",
      "[1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1, 2, 3, 4, 5, 6, 7])\n",
    "\n",
    "print(a[3])\n",
    "\n",
    "print(a[-1])\n",
    "\n",
    "print(a[2: 5])\n",
    "\n",
    "print(a[2: ])\n",
    "\n",
    "print(a[ :4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9f2863",
   "metadata": {},
   "source": [
    "다차원 배열의 경우 넘파이는 유용한 인덱싱과 슬라이싱 기능을 제공한다.\n",
    "이 경우 인덱싱은 축을 기준으로 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1d727a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "[2 5 8]\n",
      "[7 8 9]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[ 1, 2, 3],\n",
    "              [ 4, 5, 6],\n",
    "              [ 7, 8, 9]])\n",
    "\n",
    "print(a[1, 2])\n",
    "print(a[ : , 1])\n",
    "print(a[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3466de4e",
   "metadata": {},
   "source": [
    "#### 넘파이를 이용한 배열 형태 변환\n",
    "\n",
    "배열을 사용하다 보면 배열의 형태를 바꿔야 할 때가 자주 있다.\n",
    "이때 넘파이는 배열의 형태를 쉽게 바꿀 수 있는 여러 함수를 제공한다.\n",
    "\n",
    "- numpy.ravel()\n",
    "    배열을 1차원 배열로 만든다.\n",
    "- numpy.reshape()\n",
    "    배열의 형태를 바꾼다.\n",
    "- numpy.T\n",
    "    트랜스포즈된 배열을 만든다. 행렬의 트랜스포즈와 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3b445262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "[[ 1  2  3  4  5  6]\n",
      " [ 7  8  9 10 11 12]]\n",
      "[[ 1  5  9]\n",
      " [ 2  6 10]\n",
      " [ 3  7 11]\n",
      " [ 4  8 12]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1, 2, 3, 4],\n",
    "              [5, 6, 7, 8],\n",
    "              [9,10,11,12]])\n",
    "\n",
    "print(a.ravel())\n",
    "print(a.reshape(2, 6))\n",
    "print(a.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d10152b",
   "metadata": {},
   "source": [
    "reshape의 경우 특정한 행, 열만 지정해도 나머지는 자동으로 맞출 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4b645cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9 10 11 12]]\n"
     ]
    }
   ],
   "source": [
    "print(a.reshape(3, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f199c9",
   "metadata": {},
   "source": [
    "#### 넘파이 브로드캐스팅\n",
    "\n",
    "배열의 경우 두 배열의 행텨가 같아야만 사용할 수 있는 연산이 많다.\n",
    "하지만 넘파이는 브로드캐스팅이라는 기능을 통해 다른 형태의 배열끼리도 연산이 가능하게 만들어 준다.\n",
    "예를 들면, 작은 크기의 배열을 큰 크기의 배열에 더하고 싶을 때 반복문을 사용하지 않고도 더할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b962f2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  2  4]\n",
      " [ 5  5  7]\n",
      " [ 8  8 10]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1,2,3], [4,5,6], [7,8,9]])\n",
    "b = np.array([1,0,1])\n",
    "y = np.empty_like(a)\n",
    "\n",
    "for i in range(3):\n",
    "    y[i, : ] = a[i, : ] + b\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c969b75",
   "metadata": {},
   "source": [
    "위와 같은 방식으로 각 행에 배열을 더할 수 있지만 배열이 커질수록 위와 같은 반복문은 매우 느려질 수 있다.\n",
    "이러한 경우 브로드캐스팅을 사용하면 반복문 없이 매우 간단하게 계산할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c555dd58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  2  4]\n",
      " [ 5  5  7]\n",
      " [ 8  8 10]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1,2,3], [4,5,6], [7,8,9]])\n",
    "b = np.array([1,0,1])\n",
    "\n",
    "c = a + b\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8d5ea7",
   "metadata": {},
   "source": [
    "브로드캐스팅을 사용하면 위와 같이 반복문을 작성하는 수고스러움도 줄고 연산 속도도 배열의 크기가 크다면 매우 빠르다는 것을 알 수 있다.\n",
    "이처럼 넘파이를 이용하면 배열이나 행렬을 다룰 때 시간 및 효율성 측면에서 매우 우수하기 때문에 주로 행렬 혹은 벡터 데이터를 다루는 머신러닝,\n",
    "딥러닝 분야에서는 넘파이가 필수적인 라이브러리로 인식되고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c18dc6",
   "metadata": {},
   "source": [
    "### Pandas(생략)\n",
    "### Matplotlib(생략)\n",
    "### re(생략)\n",
    "### BeautifulSoup(생략)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37c9fec",
   "metadata": {},
   "source": [
    "### Kaggle\n",
    "\n",
    "```shell\n",
    "pip install kaggle\n",
    "\n",
    "# 캐글로부터 대회 데이터 다운 받기\n",
    "kaggle competitions download -c <competition-name>\n",
    "\n",
    "# 데이터 목록 확인\n",
    "kaggle competitions files -c <competition-name>\n",
    "\n",
    "# 데이터 제출\n",
    "kaggle competitions submit <competition-name> -f <file-name> -m <message>\n",
    "\n",
    "# 대회 목록 확인\n",
    "kaggle competitions list\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
